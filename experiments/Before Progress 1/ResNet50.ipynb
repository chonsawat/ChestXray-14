{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f8279a02-967b-4a26-8245-1e33490e2708",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jovyan/ChestXray-14\n"
     ]
    }
   ],
   "source": [
    "%cd ~/ChestXray-14/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "80a312c9-7f08-4476-bb7a-f22b9e37cca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Chonsawat Path: input_path = \"/content/drive/MyDrive/KKU /Project/Dataset/ChestXray NIH\"\n",
    "Deepnote Path: input_path = \"/datasets/chonsawat-drive/KKU /Project/Dataset/ChestXray NIH\"\n",
    "Elab Path: input_path = \"~/ChestXray-14/dataset/ChestXray NIH\"\n",
    "\"\"\"\n",
    "input_path = \"dataset/ChestXray NIH\"\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from tqdm.notebook import tqdm\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "37083be1-c626-4629-bea8-c7f576843254",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using tensorflow 2.8.1\n"
     ]
    }
   ],
   "source": [
    "STRATEGY = tf.distribute.get_strategy()    \n",
    "BATCH_SIZE = 16\n",
    "IMG_SIZE = 224\n",
    "SEED = 42\n",
    "    \n",
    "print('Using tensorflow %s' % tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d8a398e-32c7-4887-8de6-b9ae70468d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_map = {\n",
    "    'image': tf.io.FixedLenFeature([], tf.string),\n",
    "    'image_id': tf.io.FixedLenFeature([], tf.string),\n",
    "    'No Finding': tf.io.FixedLenFeature([], tf.int64),\n",
    "    'Atelectasis': tf.io.FixedLenFeature([], tf.int64),\n",
    "    'Consolidation': tf.io.FixedLenFeature([], tf.int64),\n",
    "    'Infiltration': tf.io.FixedLenFeature([], tf.int64),\n",
    "    'Pneumothorax': tf.io.FixedLenFeature([], tf.int64),\n",
    "    'Edema': tf.io.FixedLenFeature([], tf.int64),\n",
    "    'Emphysema': tf.io.FixedLenFeature([], tf.int64),\n",
    "    'Fibrosis': tf.io.FixedLenFeature([], tf.int64),\n",
    "    'Effusion': tf.io.FixedLenFeature([], tf.int64),\n",
    "    'Pneumonia': tf.io.FixedLenFeature([], tf.int64),\n",
    "    'Pleural_Thickening': tf.io.FixedLenFeature([], tf.int64),\n",
    "    'Cardiomegaly': tf.io.FixedLenFeature([], tf.int64),\n",
    "    'Nodule': tf.io.FixedLenFeature([], tf.int64),\n",
    "    'Mass': tf.io.FixedLenFeature([], tf.int64),\n",
    "    'Hernia': tf.io.FixedLenFeature([], tf.int64)}\n",
    "\n",
    "\n",
    "def count_data_items(filenames):\n",
    "    return np.sum([int(x[:-6].split('-')[-1]) for x in filenames])\n",
    "\n",
    "\n",
    "def decode_image(image_data):\n",
    "    image = tf.image.decode_jpeg(image_data, channels=1)\n",
    "    image = tf.reshape(image, [IMG_SIZE, IMG_SIZE, 1])\n",
    "    return image\n",
    "\n",
    "\n",
    "def scale_image(image, target):\n",
    "    image = tf.cast(image, tf.float32) / 255.\n",
    "    return image, target\n",
    "\n",
    "\n",
    "def read_tfrecord(example):\n",
    "    example = tf.io.parse_single_example(example, feature_map)\n",
    "    image = decode_image(example['image'])\n",
    "    target = [\n",
    "        example['No Finding'],\n",
    "        example['Atelectasis'],\n",
    "        example['Consolidation'],\n",
    "        example['Infiltration'],\n",
    "        example['Pneumothorax'],\n",
    "        example['Edema'],\n",
    "        example['Emphysema'],\n",
    "        example['Fibrosis'],\n",
    "        example['Effusion'],\n",
    "        example['Pneumonia'],\n",
    "        example['Pleural_Thickening'],\n",
    "        example['Cardiomegaly'],\n",
    "        example['Nodule'],\n",
    "        example['Mass'],\n",
    "        example['Hernia']]\n",
    "    return image, target\n",
    "\n",
    "\n",
    "def data_augment(image, target):\n",
    "    image = tf.image.random_flip_left_right(image, seed=SEED)\n",
    "    image = tf.image.random_flip_up_down(image, seed=SEED)\n",
    "    return image, target\n",
    "\n",
    "\n",
    "def get_dataset(filenames, shuffled=False, repeated=False, \n",
    "                cached=False, augmented=False, distributed=True):\n",
    "    auto = tf.data.experimental.AUTOTUNE\n",
    "    dataset = tf.data.TFRecordDataset(filenames, num_parallel_reads=auto)\n",
    "    dataset = dataset.map(read_tfrecord, num_parallel_calls=auto)\n",
    "    if augmented:\n",
    "        dataset = dataset.map(data_augment, num_parallel_calls=auto)\n",
    "    dataset = dataset.map(scale_image, num_parallel_calls=auto)\n",
    "    if shuffled:\n",
    "        dataset = dataset.shuffle(2048, seed=SEED)\n",
    "    if repeated:\n",
    "        dataset = dataset.repeat()\n",
    "    dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)\n",
    "    if cached:\n",
    "        dataset = dataset.cache()\n",
    "    dataset = dataset.prefetch(auto)\n",
    "    if distributed:\n",
    "        dataset = STRATEGY.experimental_distribute_dataset(dataset)\n",
    "    return dataset\n",
    "\n",
    "\n",
    "def get_model():\n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.applications.EfficientNetB0(\n",
    "            include_top=False,\n",
    "            input_shape=(None, None, 1),\n",
    "            weights=None,\n",
    "            pooling='avg'),\n",
    "        tf.keras.layers.Dense(15, activation='sigmoid')\n",
    "    ])\n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=tf.keras.metrics.AUC(multi_label=True))\n",
    "\n",
    "    return model\n",
    "\n",
    "def get_resnet50_model():\n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.applications.resnet50.ResNet50(\n",
    "            include_top=False, \n",
    "            input_shape=(None, None, 1), \n",
    "            weights=None,\n",
    "            pooling='avg'\n",
    "            # classes=1000,\n",
    "        ),\n",
    "        tf.keras.layers.Dense(15, activation='sigmoid')\n",
    "    ])\n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss='binary_crossentropy',\n",
    "        run_eagerly=True,\n",
    "        metrics=tf.keras.metrics.AUC(multi_label=True))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f5e56761-1591-4d5a-ae71-ac22eab5011d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-13 07:10:59.401505: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "   2/4905 [..............................] - ETA: 11:31:56 - loss: 0.8396 - auc: 0.1856WARNING:tensorflow:5 out of the last 5 calls to <function pfor.<locals>.f at 0x7fda041833a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function pfor.<locals>.f at 0x7fda041833a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "4905/4905 [==============================] - 20404s 4s/step - loss: 0.2190 - auc: 0.5674 - val_loss: 0.2828 - val_auc: 0.5809\n",
      "Epoch 2/5\n",
      "4905/4905 [==============================] - 20095s 4s/step - loss: 0.2112 - auc: 0.6127 - val_loss: 0.2121 - val_auc: 0.6345\n",
      "Epoch 3/5\n",
      "4905/4905 [==============================] - 19948s 4s/step - loss: 0.2079 - auc: 0.6409 - val_loss: 0.2076 - val_auc: 0.6533\n",
      "Epoch 4/5\n",
      "4905/4905 [==============================] - 19916s 4s/step - loss: 0.2052 - auc: 0.6609 - val_loss: 0.2081 - val_auc: 0.6748\n",
      "Epoch 5/5\n",
      "4905/4905 [==============================] - 19945s 4s/step - loss: 0.2030 - auc: 0.6764 - val_loss: 0.2009 - val_auc: 0.6910\n"
     ]
    }
   ],
   "source": [
    "train_filenames = tf.io.gfile.glob(f'{input_path}/data/224x224/train/*.tfrec')\n",
    "val_filenames = tf.io.gfile.glob(f'{input_path}/data/224x224/valid/*.tfrec')\n",
    "test_filenames = tf.io.gfile.glob(f'{input_path}/data/224x224/test/*.tfrec')\n",
    "\n",
    "steps_per_epoch = count_data_items(train_filenames) // BATCH_SIZE\n",
    "validation_steps = count_data_items(val_filenames) // BATCH_SIZE\n",
    "\n",
    "train_dataset = get_dataset(train_filenames, shuffled=True, repeated=True, augmented=True)\n",
    "val_dataset = get_dataset(val_filenames, cached=True)\n",
    "\n",
    "with STRATEGY.scope():\n",
    "    model = get_resnet50_model()\n",
    "    \n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    epochs=5,\n",
    "    validation_data=val_dataset,\n",
    "    validation_steps=validation_steps,\n",
    "    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1270e84c-affd-4415-b792-10966672e438",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(f\"{input_path}/models/Resnet50.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ddbefa-5178-4e52-93f3-3974c3d81873",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
