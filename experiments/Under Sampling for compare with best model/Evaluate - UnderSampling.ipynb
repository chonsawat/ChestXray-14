{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "928302db-884a-441d-bf11-f999b5a8fcce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Collecting tensorflow_addons\n",
      "  Downloading tensorflow_addons-0.19.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h\u001b[33mWARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ReadTimeoutError(\"HTTPSConnectionPool(host='developer.download.nvidia.com', port=443): Read timed out. (read timeout=15)\")': /compute/redist/typeguard/\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=3, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ConnectTimeoutError(<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7f612dec3520>, 'Connection to developer.download.nvidia.com timed out. (connect timeout=15)')': /compute/redist/typeguard/\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7f612dec37c0>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /compute/redist/typeguard/\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7f612dec39a0>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /compute/redist/typeguard/\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7f612dec3b80>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /compute/redist/typeguard/\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting typeguard>=2.7\n",
      "  Downloading typeguard-2.13.3-py3-none-any.whl (17 kB)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from tensorflow_addons) (21.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->tensorflow_addons) (3.0.9)\n",
      "Installing collected packages: typeguard, tensorflow_addons\n",
      "Successfully installed tensorflow_addons-0.19.0 typeguard-2.13.3\n",
      "\u001b[33mWARNING: There was an error checking the latest version of pip.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip3 install tensorflow_addons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "49bfdc98-319c-497f-a9ee-34b3cfcf752d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/jovyan/ChestXray-14')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7739146d-c2dd-441c-948b-8a9d4ea282f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-13 17:34:36.561960: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "\n",
    "from modules.utils import get_dataset\n",
    "from modules.dataset import LABELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "76728576-9809-4f19-bf73-e7268ae50a19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jovyan/ChestXray-14/experiments/Under Sampling for compare with best model'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "CURRENT_PATH = os.path.abspath(\"\")\n",
    "CURRENT_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0a5cf089-e03c-484c-8938-c7a7c325fb30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jovyan/ChestXray-14/experiments/Under Sampling for compare with best model/results/evaluate/cross_entropy/EfficientNetB0_None'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RESULT_EVALUATE_PATH = os.path.join(CURRENT_PATH, \"results\", \"evaluate\", \"cross_entropy\", \"EfficientNetB0_None\")\n",
    "RESULT_EVALUATE_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8b9cbf21-3ab7-48b6-bdd0-6916d7c00866",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "Path(RESULT_EVALUATE_PATH).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "93b9d419-7180-4e46-baba-ef0e61d56396",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset:\n",
    "    INPUT_PATH = \"/home/jovyan/ChestXray-14/dataset/ChestXray NIH\"\n",
    "    \n",
    "    def get_train(self):\n",
    "        filenames = tf.io.gfile.glob(f'{self.INPUT_PATH}/data/Under_Sampling_on_fold_3_dataset/train/*.tfrec')\n",
    "        dataset = get_dataset(filenames)\n",
    "        return dataset\n",
    "\n",
    "    def get_test(self):\n",
    "        filenames = tf.io.gfile.glob(f'{self.INPUT_PATH}/data/Under_Sampling_on_fold_3_dataset/test/*.tfrec')\n",
    "        dataset = get_dataset(filenames)\n",
    "        return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "86dcbf37-dba1-4563-b901-d75b09dc1537",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-13 17:34:38.616790: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-13 17:34:40.416918: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 31679 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:b1:00.0, compute capability: 8.0\n"
     ]
    }
   ],
   "source": [
    "test_dataset = Dataset().get_test()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a36ec3de-064c-47be-b49e-2783f22f56c6",
   "metadata": {},
   "source": [
    "## Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9073b134-f958-4389-a98c-2a100ed9be51",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "ROOT_PATH = \"/home/jovyan/ChestXray-14\"\n",
    "num_class = 15 # TODO: change to 15 for multi-labels\n",
    "\n",
    "class Evaluate:\n",
    "    def __init__(self, model_path):\n",
    "        self.y_true = None\n",
    "        self.y_preds = None\n",
    "        self.model_path = model_path\n",
    "        self.model = self.get_model(model_path)\n",
    "        self.best_thresholds = None\n",
    "        self.thresholds_200 = None\n",
    "    \n",
    "    def get_model(self, path):\n",
    "        return tf.keras.models.load_model(path)\n",
    "    \n",
    "    def get_y_true(self, data):\n",
    "        y_true=[]\n",
    "        for X,y in data:\n",
    "            for label in y:\n",
    "                y_true.append(label)\n",
    "        y_true = tf.Variable(y_true)\n",
    "        self.y_true = y_true\n",
    "        return y_true\n",
    "\n",
    "    def get_confusion_metrics(self, y_true, y_preds):\n",
    "        m = tf.keras.metrics.AUC(multi_label=True)\n",
    "        m.update_state(y_true, y_preds)\n",
    "\n",
    "        thresholds = m.thresholds\n",
    "        variables = m.variables\n",
    "        TP = variables[0]\n",
    "        TN = variables[1]\n",
    "        FP = variables[2]\n",
    "        FN = variables[3]\n",
    "        return thresholds, TP, TN, FP, FN\n",
    "\n",
    "    def model_predict(self, test_dataset):\n",
    "        return self.model.predict(test_dataset)\n",
    "\n",
    "    def get_f1_scores_200_thresholds(self, test_dataset):\n",
    "        self.y_true = self.get_y_true(test_dataset)\n",
    "        self.y_preds = self.model_predict(test_dataset)\n",
    "        \n",
    "        confusion_metrics = self.get_confusion_metrics(self.y_true, self.y_preds)\n",
    "        thresholds, TP, TN, FP, FN = confusion_metrics\n",
    "        self.thresholds_200 = thresholds\n",
    "        f1_class_dict = dict()\n",
    "        for i in range(len(thresholds)):\n",
    "            tp, tn, fp, fn = TP[i], TN[i], FP[i], FN[i]\n",
    "            for label_index in range(num_class):\n",
    "                f1_score = 2*tp[label_index] / (2*tp[label_index] + fp[label_index] + fn[label_index])\n",
    "                try:\n",
    "                    f1_class_dict[LABELS[label_index]].append(f1_score)\n",
    "                except KeyError:\n",
    "                    f1_class_dict[LABELS[label_index]] = [f1_score]\n",
    "        print(LABELS)\n",
    "        return f1_class_dict\n",
    "    \n",
    "    def get_f1_scores(self, test_dataset):\n",
    "        self.y_true = self.get_y_true(test_dataset)\n",
    "        self.y_preds = self.model_predict(test_dataset)\n",
    "        metric = tfa.metrics.MultiLabelConfusionMatrix(num_classes=num_class)\n",
    "        metric.update_state(self.y_true,\n",
    "                            np.greater_equal(self.y_preds, self.best_thresholds).astype('int8'))\n",
    "        result = metric.result()\n",
    "        \n",
    "        f1_class_dict = dict()\n",
    "        for idx, confusion in enumerate(result):\n",
    "            label = LABELS[idx]\n",
    "            TP, TN, FP, FN = (confusion[1, 1],\n",
    "                              confusion[0, 0],\n",
    "                              confusion[0, 1],\n",
    "                              confusion[1, 0])\n",
    "            f1_score = 2*TP / (2*TP + FP + FN)\n",
    "            f1_class_dict[label] = [f1_score.numpy()]\n",
    "        return f1_class_dict\n",
    "    \n",
    "    def get_precision_scores(self, test_dataset, new_calculate=True):\n",
    "        if new_calculate is True:\n",
    "            self.y_true = self.get_y_true(test_dataset)\n",
    "            self.y_preds = self.model_predict(test_dataset)\n",
    "        metric = tfa.metrics.MultiLabelConfusionMatrix(num_classes=num_class)\n",
    "        metric.update_state(self.y_true,\n",
    "                            np.greater_equal(self.y_preds, self.best_thresholds).astype('int8'))\n",
    "        result = metric.result()\n",
    "        \n",
    "        precision_class_dict = dict()\n",
    "        for idx, confusion in enumerate(result):\n",
    "            label = LABELS[idx]\n",
    "            TP, TN, FP, FN = (confusion[1, 1],\n",
    "                              confusion[0, 0],\n",
    "                              confusion[0, 1],\n",
    "                              confusion[1, 0])\n",
    "            precision = TP / (TP + FP)\n",
    "            precision_class_dict[label] = [precision.numpy()]\n",
    "        return precision_class_dict\n",
    "    \n",
    "    def get_recall_scores(self, test_dataset, new_calculate=True):\n",
    "        if new_calculate is True:\n",
    "            self.y_true = self.get_y_true(test_dataset)\n",
    "            self.y_preds = self.model_predict(test_dataset)\n",
    "        metric = tfa.metrics.MultiLabelConfusionMatrix(num_classes=num_class)\n",
    "        metric.update_state(self.y_true,\n",
    "                            np.greater_equal(self.y_preds, self.best_thresholds).astype('int8'))\n",
    "        result = metric.result()\n",
    "        \n",
    "        recall_class_dict = dict()\n",
    "        for idx, confusion in enumerate(result):\n",
    "            label = LABELS[idx]\n",
    "            TP, TN, FP, FN = (confusion[1, 1],\n",
    "                              confusion[0, 0],\n",
    "                              confusion[0, 1],\n",
    "                              confusion[1, 0])\n",
    "            recall = TP / (TP + FN)\n",
    "            recall_class_dict[label] = [recall.numpy()]\n",
    "        return recall_class_dict\n",
    "    \n",
    "    def get_best_threshold(self,\n",
    "                           test_dataset=None,\n",
    "                           save_best_thresholds=f\"{ROOT_PATH}/results/paper/table3_1/best_thresholds.csv\",\n",
    "                           save_200_thresholds=f\"{ROOT_PATH}/results/paper/table3_1/f1_per_thresholds.csv\"):\n",
    "        if test_dataset is None:\n",
    "            fold_num = int(self.model_path.split(\".\")[0][-1])\n",
    "            test_dataset = datasets[fold_num-1]\n",
    "        \n",
    "        f1_scores_dict = self.get_f1_scores_200_thresholds(test_dataset)\n",
    "        best_thresholds_dict = {\"thresholds\": [], \"f1_most\": [], \"label\": []}\n",
    "        for key, value in f1_scores_dict.items():\n",
    "            f1_arg_max = np.argmax(value)\n",
    "            best_thresholds_dict[\"f1_most\"].append(value[f1_arg_max].numpy())\n",
    "            best_thresholds_dict[\"label\"].append(key)\n",
    "            best_thresholds_dict[\"thresholds\"].append(self.thresholds_200[f1_arg_max])\n",
    "        \n",
    "        df = pd.DataFrame(best_thresholds_dict)\n",
    "        df = df.set_index(\"label\")\n",
    "        df.to_csv(save_best_thresholds, index=True)\n",
    "        print(f\"{save_best_thresholds} was success!\")\n",
    "        # print(df)\n",
    "        \n",
    "        df_200_thresholds = pd.DataFrame(f1_scores_dict)\n",
    "        df_200_thresholds.to_csv(save_200_thresholds, index=True)\n",
    "        print(f\"{save_200_thresholds} was success!\")\n",
    "        self.best_thresholds = df.copy()[\"thresholds\"].values\n",
    "\n",
    "    def __enter__(self):\n",
    "        print(\"Doing ...!\")\n",
    "        return self\n",
    "\n",
    "    def __exit__(self, *arg):\n",
    "        self.y_true = None\n",
    "        self.y_preds = None\n",
    "        print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6de880d4-ab4b-4dd9-90aa-46e3f320c414",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-13 17:34:49.948820: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8100\n",
      "2023-03-13 17:34:51.192025: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-03-13 17:34:51.193401: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-03-13 17:34:51.193463: W tensorflow/stream_executor/gpu/asm_compiler.cc:80] Couldn't get ptxas version string: INTERNAL: Couldn't invoke ptxas --version\n",
      "2023-03-13 17:34:51.194992: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-03-13 17:34:51.195151: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] INTERNAL: Failed to launch ptxas\n",
      "Relying on driver to perform ptx compilation. \n",
      "Modify $PATH to customize ptxas location.\n",
      "This message will be only logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      5/Unknown - 9s 31ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-13 17:34:55.677964: I tensorflow/stream_executor/cuda/cuda_blas.cc:1786] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1402/1402 [==============================] - 50s 29ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.2312185 , 0.3596831 , 0.06779961, ..., 0.08386638, 0.067361  ,\n",
       "        0.00561023],\n",
       "       [0.04511511, 0.20810753, 0.05330588, ..., 0.10672587, 0.14850117,\n",
       "        0.00069789],\n",
       "       [0.07334991, 0.25200266, 0.10869298, ..., 0.07620022, 0.10358183,\n",
       "        0.00110502],\n",
       "       ...,\n",
       "       [0.30976817, 0.02007885, 0.03837766, ..., 0.14225575, 0.06074484,\n",
       "        0.00066796],\n",
       "       [0.23619632, 0.06399193, 0.05297049, ..., 0.13383512, 0.09866322,\n",
       "        0.00164709],\n",
       "       [0.20307364, 0.25396195, 0.04335382, ..., 0.1367706 , 0.14343172,\n",
       "        0.01060693]], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Delete when test done\n",
    "MODEL_PATH = f'{CURRENT_PATH}/results/models/cross_entropy/EfficientNetB0_None.h5'\n",
    "y_preds = Evaluate(MODEL_PATH).model_predict(test_dataset)\n",
    "y_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2dc0c9a1-2a79-407d-8961-e6630c659fc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=(22424, 15) dtype=int64, numpy=\n",
       "array([[0, 1, 0, ..., 0, 0, 0],\n",
       "       [0, 1, 0, ..., 0, 0, 0],\n",
       "       [1, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [1, 0, 0, ..., 0, 0, 0],\n",
       "       [1, 0, 0, ..., 0, 0, 0],\n",
       "       [1, 0, 0, ..., 0, 0, 0]])>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true = Evaluate(MODEL_PATH).get_y_true(test_dataset)\n",
    "y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "95f161dc-c678-499e-9b65-94956a35fd39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PrefetchDataset element_spec=(TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None, 15), dtype=tf.int64, name=None))>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ed0ad33-18d0-4dc8-8466-3e3eabd50c71",
   "metadata": {},
   "source": [
    "## Using"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "38f88be4-7289-4e5b-892c-8a5eb55a7d0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1402/1402 [==============================] - 42s 29ms/step\n",
      "['No Finding', 'Atelectasis', 'Consolidation', 'Infiltration', 'Pneumothorax', 'Edema', 'Emphysema', 'Fibrosis', 'Effusion', 'Pneumonia', 'Pleural_Thickening', 'Cardiomegaly', 'Nodule', 'Mass', 'Hernia']\n",
      "/home/jovyan/ChestXray-14/experiments/Under Sampling for compare with best model/results/evaluate/cross_entropy/EfficientNetB0_None/best_thresholds.csv was success!\n",
      "/home/jovyan/ChestXray-14/experiments/Under Sampling for compare with best model/results/evaluate/cross_entropy/EfficientNetB0_None/f1_per_thresholds.csv was success!\n",
      "Doing ...!\n",
      "1402/1402 [==============================] - 40s 28ms/step\n",
      "{'No Finding': [0.72972876], 'Atelectasis': [0.32100025], 'Consolidation': [0.20004588], 'Infiltration': [0.3447727], 'Pneumothorax': [0.2805851], 'Edema': [0.20034945], 'Emphysema': [0.13678373], 'Fibrosis': [0.07763975], 'Effusion': [0.43890765], 'Pneumonia': [0.06167401], 'Pleural_Thickening': [0.1637044], 'Cardiomegaly': [0.26753977], 'Nodule': [0.12905757], 'Mass': [0.2004008], 'Hernia': [0.017953321]}\n",
      "   No Finding  Atelectasis  Consolidation  Infiltration  Pneumothorax  \\\n",
      "0    0.729729        0.321       0.200046      0.344773      0.280585   \n",
      "\n",
      "      Edema  Emphysema  Fibrosis  Effusion  Pneumonia  Pleural_Thickening  \\\n",
      "0  0.200349   0.136784   0.07764  0.438908   0.061674            0.163704   \n",
      "\n",
      "   Cardiomegaly    Nodule      Mass    Hernia  \n",
      "0       0.26754  0.129058  0.200401  0.017953  \n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "MODEL_PATH = f'{CURRENT_PATH}/results/models/cross_entropy/EfficientNetB0_None.h5'\n",
    "best_model = Evaluate(MODEL_PATH)\n",
    "best_model.get_best_threshold(\n",
    "    test_dataset=test_dataset,\n",
    "    save_best_thresholds=f\"{RESULT_EVALUATE_PATH}/best_thresholds.csv\",\n",
    "    save_200_thresholds=f\"{RESULT_EVALUATE_PATH}/f1_per_thresholds.csv\"\n",
    ")\n",
    "\n",
    "with best_model:\n",
    "    f1_each_class = best_model.get_f1_scores(test_dataset)\n",
    "    print(f1_each_class)\n",
    "    df = pd.DataFrame(f1_each_class)\n",
    "    df.to_csv(f\"{RESULT_EVALUATE_PATH}/f1_scores.csv\", index=False)\n",
    "\n",
    "    precision_each_class = best_model.get_precision_scores(test_dataset, new_calculate=False)\n",
    "    pd.DataFrame(precision_each_class)\\\n",
    "        .to_csv(f\"{RESULT_EVALUATE_PATH}/precision.csv\", index=False)\n",
    "\n",
    "    recall_each_class = best_model.get_recall_scores(test_dataset, new_calculate=False)\n",
    "    pd.DataFrame(recall_each_class)\\\n",
    "        .to_csv(f\"{RESULT_EVALUATE_PATH}/recall.csv\", index=False)\n",
    "\n",
    "    print(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
