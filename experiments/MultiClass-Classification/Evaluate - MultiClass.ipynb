{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "928302db-884a-441d-bf11-f999b5a8fcce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow_addons in /opt/conda/lib/python3.10/site-packages (0.20.0)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from tensorflow_addons) (21.3)\n",
      "Requirement already satisfied: typeguard<3.0.0,>=2.7 in /opt/conda/lib/python3.10/site-packages (from tensorflow_addons) (2.13.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->tensorflow_addons) (3.0.9)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install tensorflow_addons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "49bfdc98-319c-497f-a9ee-34b3cfcf752d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/jovyan/ChestXray-14')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7739146d-c2dd-441c-948b-8a9d4ea282f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-09 19:23:18.968740: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "/opt/conda/lib/python3.10/site-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n",
      "\n",
      "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
      "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
      "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
      "\n",
      "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
      "\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/tensorflow_addons/utils/ensure_tf_install.py:53: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.10.0 and strictly below 2.13.0 (nightly versions are not supported). \n",
      " The versions of TensorFlow you are currently using is 2.9.1 and is not supported. \n",
      "Some things might work, some things might not.\n",
      "If you were to encounter a bug, do not file an issue.\n",
      "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
      "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
      "https://github.com/tensorflow/addons\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "\n",
    "from modules.utils import get_dataset\n",
    "from modules.dataset import LABELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cea76338-b06c-4dc8-975d-ce4418a2531e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b9cbf21-3ab7-48b6-bdd0-6916d7c00866",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "76728576-9809-4f19-bf73-e7268ae50a19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jovyan/ChestXray-14/experiments/MultiClass-Classification'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CURRENT_PATH = os.path.abspath(\"\")\n",
    "CURRENT_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "266bf9c6-86c1-48b5-923b-d2374cd84d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_class = 15 # TODO: change to 15 for multi-labels\n",
    "ROOT_PATH = \"/home/jovyan/ChestXray-14\"\n",
    "INPUT_PATH = f\"{ROOT_PATH}/dataset/ChestXray NIH\"\n",
    "EXPERIMENT_NAME = \"multiclass_classification_with_cross_entropy_loss_2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "93b9d419-7180-4e46-baba-ef0e61d56396",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset:\n",
    "    INPUT_PATH = INPUT_PATH\n",
    "    \n",
    "    def __init__(self, fold_num):\n",
    "        self.fold_num = fold_num\n",
    "    \n",
    "    def get_train(self):\n",
    "        filenames = tf.io.gfile.glob(f'{self.INPUT_PATH}/data/multiclass_dataset/folds/fold{self.fold_num}/train/*.tfrec')\n",
    "        dataset = get_dataset(filenames)\n",
    "        return dataset\n",
    "\n",
    "    def get_test(self):\n",
    "        filenames = tf.io.gfile.glob(f'{self.INPUT_PATH}/data/multiclass_dataset/folds/fold{self.fold_num}/test/*.tfrec')\n",
    "        dataset = get_dataset(filenames)\n",
    "        return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a36ec3de-064c-47be-b49e-2783f22f56c6",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9073b134-f958-4389-a98c-2a100ed9be51",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Evaluate:\n",
    "    def __init__(self, model_path):\n",
    "        self.y_true = None\n",
    "        self.y_preds = None\n",
    "        self.model_path = model_path\n",
    "        self.model = self.get_model(model_path)\n",
    "        self.best_thresholds = None\n",
    "        self.thresholds_200 = None\n",
    "    \n",
    "    def get_model(self, path):\n",
    "        return tf.keras.models.load_model(path)\n",
    "    \n",
    "    def get_y_true(self, data):\n",
    "        y_true=[]\n",
    "        for X,y in data:\n",
    "            for label in y:\n",
    "                y_true.append(label)\n",
    "        y_true = tf.Variable(y_true)\n",
    "        self.y_true = y_true\n",
    "        return y_true\n",
    "\n",
    "    def get_confusion_metrics(self, y_true, y_preds):\n",
    "        m = tf.keras.metrics.AUC(multi_label=True)\n",
    "        m.update_state(y_true, y_preds)\n",
    "\n",
    "        thresholds = m.thresholds\n",
    "        variables = m.variables\n",
    "        TP = variables[0]\n",
    "        TN = variables[1]\n",
    "        FP = variables[2]\n",
    "        FN = variables[3]\n",
    "        return thresholds, TP, TN, FP, FN\n",
    "\n",
    "    def model_predict(self, test_dataset):\n",
    "        return self.model.predict(test_dataset)\n",
    "\n",
    "    def get_f1_scores_200_thresholds(self, test_dataset):\n",
    "        self.y_true = self.get_y_true(test_dataset)\n",
    "        self.y_preds = self.model_predict(test_dataset)\n",
    "        \n",
    "        confusion_metrics = self.get_confusion_metrics(self.y_true, self.y_preds)\n",
    "        thresholds, TP, TN, FP, FN = confusion_metrics\n",
    "        self.thresholds_200 = thresholds\n",
    "        f1_class_dict = dict()\n",
    "        for i in range(len(thresholds)):\n",
    "            tp, tn, fp, fn = TP[i], TN[i], FP[i], FN[i]\n",
    "            for label_index in range(num_class):\n",
    "                f1_score = 2*tp[label_index] / (2*tp[label_index] + fp[label_index] + fn[label_index])\n",
    "                try:\n",
    "                    f1_class_dict[LABELS[label_index]].append(f1_score)\n",
    "                except KeyError:\n",
    "                    f1_class_dict[LABELS[label_index]] = [f1_score]\n",
    "        print(LABELS)\n",
    "        return f1_class_dict\n",
    "    \n",
    "    def get_f1_scores(self, test_dataset):\n",
    "        self.y_true = self.get_y_true(test_dataset)\n",
    "        self.y_preds = self.model_predict(test_dataset)\n",
    "        metric = tfa.metrics.MultiLabelConfusionMatrix(num_classes=num_class)\n",
    "        metric.update_state(self.y_true,\n",
    "                            np.greater_equal(self.y_preds, self.best_thresholds).astype('int8'))\n",
    "        result = metric.result()\n",
    "        \n",
    "        f1_class_dict = dict()\n",
    "        for idx, confusion in enumerate(result):\n",
    "            label = LABELS[idx]\n",
    "            TP, TN, FP, FN = (confusion[1, 1],\n",
    "                              confusion[0, 0],\n",
    "                              confusion[0, 1],\n",
    "                              confusion[1, 0])\n",
    "            f1_score = 2*TP / (2*TP + FP + FN)\n",
    "            f1_class_dict[label] = [f1_score.numpy()]\n",
    "        return f1_class_dict\n",
    "    \n",
    "    def get_precision_scores(self, test_dataset, new_calculate=True):\n",
    "        if new_calculate is True:\n",
    "            self.y_true = self.get_y_true(test_dataset)\n",
    "            self.y_preds = self.model_predict(test_dataset)\n",
    "        metric = tfa.metrics.MultiLabelConfusionMatrix(num_classes=num_class)\n",
    "        metric.update_state(self.y_true,\n",
    "                            np.greater_equal(self.y_preds, self.best_thresholds).astype('int8'))\n",
    "        result = metric.result()\n",
    "        \n",
    "        precision_class_dict = dict()\n",
    "        for idx, confusion in enumerate(result):\n",
    "            label = LABELS[idx]\n",
    "            TP, TN, FP, FN = (confusion[1, 1],\n",
    "                              confusion[0, 0],\n",
    "                              confusion[0, 1],\n",
    "                              confusion[1, 0])\n",
    "            precision = TP / (TP + FP)\n",
    "            precision_class_dict[label] = [precision.numpy()]\n",
    "        return precision_class_dict\n",
    "    \n",
    "    def get_recall_scores(self, test_dataset, new_calculate=True):\n",
    "        if new_calculate is True:\n",
    "            self.y_true = self.get_y_true(test_dataset)\n",
    "            self.y_preds = self.model_predict(test_dataset)\n",
    "        metric = tfa.metrics.MultiLabelConfusionMatrix(num_classes=num_class)\n",
    "        metric.update_state(self.y_true,\n",
    "                            np.greater_equal(self.y_preds, self.best_thresholds).astype('int8'))\n",
    "        result = metric.result()\n",
    "        \n",
    "        recall_class_dict = dict()\n",
    "        for idx, confusion in enumerate(result):\n",
    "            label = LABELS[idx]\n",
    "            TP, TN, FP, FN = (confusion[1, 1],\n",
    "                              confusion[0, 0],\n",
    "                              confusion[0, 1],\n",
    "                              confusion[1, 0])\n",
    "            recall = TP / (TP + FN)\n",
    "            recall_class_dict[label] = [recall.numpy()]\n",
    "        return recall_class_dict\n",
    "    \n",
    "    def get_best_threshold(self,\n",
    "                           test_dataset=None,\n",
    "                           save_best_thresholds=f\"{ROOT_PATH}/results/paper/table3_1/best_thresholds.csv\",\n",
    "                           save_200_thresholds=f\"{ROOT_PATH}/results/paper/table3_1/f1_per_thresholds.csv\"):\n",
    "        if test_dataset is None:\n",
    "            assert ValueError(\"test dataset is None\")\n",
    "        \n",
    "        f1_scores_dict = self.get_f1_scores_200_thresholds(test_dataset)\n",
    "        best_thresholds_dict = {\"thresholds\": [], \"f1_most\": [], \"label\": []}\n",
    "        for key, value in f1_scores_dict.items():\n",
    "            f1_arg_max = np.argmax(value)\n",
    "            best_thresholds_dict[\"f1_most\"].append(value[f1_arg_max].numpy())\n",
    "            best_thresholds_dict[\"label\"].append(key)\n",
    "            best_thresholds_dict[\"thresholds\"].append(self.thresholds_200[f1_arg_max])\n",
    "        \n",
    "        df = pd.DataFrame(best_thresholds_dict)\n",
    "        df = df.set_index(\"label\")\n",
    "        df.to_csv(save_best_thresholds, index=True)\n",
    "        print(f\"{save_best_thresholds} was success!\")\n",
    "        # print(df)\n",
    "        \n",
    "        df_200_thresholds = pd.DataFrame(f1_scores_dict)\n",
    "        df_200_thresholds.to_csv(save_200_thresholds, index=True)\n",
    "        print(f\"{save_200_thresholds} was success!\")\n",
    "        self.best_thresholds = df.copy()[\"thresholds\"].values\n",
    "\n",
    "    def __enter__(self):\n",
    "        print(\"Doing ...!\")\n",
    "        return self\n",
    "\n",
    "    def __exit__(self, *arg):\n",
    "        self.y_true = None\n",
    "        self.y_preds = None\n",
    "        print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ed0ad33-18d0-4dc8-8466-3e3eabd50c71",
   "metadata": {},
   "source": [
    "## Using"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c2a41b42-8525-40e9-bd59-0784db8b1bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "11d4c2b3-4f53-4487-a122-b40171f91905",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "class TimeUsed:\n",
    "    def start(self):\n",
    "        self.start = time.time()\n",
    "     \n",
    "    def stop_and_report(self):\n",
    "        self.end = time.time()\n",
    "        print(\n",
    "            \"===== \" * 5,\n",
    "            \"Model used for: {:.2f} second(s)\".format(self.end - self.start),\n",
    "            \"===== \" * 5,\n",
    "            \"\\n\\n\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7f05c990-8093-4093-b47b-cd896ac283fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'multiclass_classification_with_cross_entropy_loss_2'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EXPERIMENT_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5bba9543-a20d-45a6-a7ee-356572e3c213",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_dataset = Dataset(fold_num).get_test()\n",
    "# MODEL_PATH = f'{CURRENT_PATH}/results/models/{EXPERIMENT_NAME}/EfficientNetB0_None_FOLD_{fold_num}.h5'\n",
    "\n",
    "# model = tf.keras.models.load_model(MODEL_PATH)\n",
    "# model = tf.config.run_functions_eagerly(True)\n",
    "# model.predict(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bd80be50-824b-4fc7-821d-bbec8843c8ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fff4decbad541c7a8b8533a3423625a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "Unexpected result of `predict_function` (Empty batch_outputs). Please use `Model.compile(..., run_eagerly=True)`, or `tf.config.run_functions_eagerly(True)` for more information of where went wrong, or file a issue/bug to `tf.keras`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [15]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m test_dataset \u001b[38;5;241m=\u001b[39m Dataset(fold_num)\u001b[38;5;241m.\u001b[39mget_test()\n\u001b[1;32m     12\u001b[0m best_model \u001b[38;5;241m=\u001b[39m Evaluate(MODEL_PATH)\n\u001b[0;32m---> 14\u001b[0m \u001b[43mbest_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_best_threshold\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtest_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43msave_best_thresholds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mRESULT_EVALUATE_PATH\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/best_thresholds.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43msave_200_thresholds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mRESULT_EVALUATE_PATH\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/f1_per_thresholds.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m     18\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m best_model:\n\u001b[1;32m     21\u001b[0m     f1_each_class \u001b[38;5;241m=\u001b[39m best_model\u001b[38;5;241m.\u001b[39mget_f1_scores(test_dataset)\n",
      "Input \u001b[0;32mIn [9]\u001b[0m, in \u001b[0;36mEvaluate.get_best_threshold\u001b[0;34m(self, test_dataset, save_best_thresholds, save_200_thresholds)\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m test_dataset \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest dataset is None\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 122\u001b[0m f1_scores_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_f1_scores_200_thresholds\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_dataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    123\u001b[0m best_thresholds_dict \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthresholds\u001b[39m\u001b[38;5;124m\"\u001b[39m: [], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mf1_most\u001b[39m\u001b[38;5;124m\"\u001b[39m: [], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m\"\u001b[39m: []}\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m f1_scores_dict\u001b[38;5;241m.\u001b[39mitems():\n",
      "Input \u001b[0;32mIn [9]\u001b[0m, in \u001b[0;36mEvaluate.get_f1_scores_200_thresholds\u001b[0;34m(self, test_dataset)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_f1_scores_200_thresholds\u001b[39m(\u001b[38;5;28mself\u001b[39m, test_dataset):\n\u001b[1;32m     38\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39my_true \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_y_true(test_dataset)\n\u001b[0;32m---> 39\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39my_preds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_dataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     41\u001b[0m     confusion_metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_confusion_metrics(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39my_true, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39my_preds)\n\u001b[1;32m     42\u001b[0m     thresholds, TP, TN, FP, FN \u001b[38;5;241m=\u001b[39m confusion_metrics\n",
      "Input \u001b[0;32mIn [9]\u001b[0m, in \u001b[0;36mEvaluate.model_predict\u001b[0;34m(self, test_dataset)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmodel_predict\u001b[39m(\u001b[38;5;28mself\u001b[39m, test_dataset):\n\u001b[0;32m---> 35\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_dataset\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/utils/traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/engine/training.py:2048\u001b[0m, in \u001b[0;36mModel.predict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   2046\u001b[0m         callbacks\u001b[38;5;241m.\u001b[39mon_predict_batch_end(end_step, {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutputs\u001b[39m\u001b[38;5;124m'\u001b[39m: batch_outputs})\n\u001b[1;32m   2047\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m batch_outputs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 2048\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUnexpected result of `predict_function` \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   2049\u001b[0m                      \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m(Empty batch_outputs). Please use \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   2050\u001b[0m                      \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m`Model.compile(..., run_eagerly=True)`, or \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   2051\u001b[0m                      \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m`tf.config.run_functions_eagerly(True)` for more \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   2052\u001b[0m                      \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minformation of where went wrong, or file a \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   2053\u001b[0m                      \u001b[38;5;124m'\u001b[39m\u001b[38;5;124missue/bug to `tf.keras`.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m   2054\u001b[0m   callbacks\u001b[38;5;241m.\u001b[39mon_predict_end()\n\u001b[1;32m   2055\u001b[0m all_outputs \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39m__internal__\u001b[38;5;241m.\u001b[39mnest\u001b[38;5;241m.\u001b[39mmap_structure_up_to(\n\u001b[1;32m   2056\u001b[0m     batch_outputs, potentially_ragged_concat, outputs)\n",
      "\u001b[0;31mValueError\u001b[0m: Unexpected result of `predict_function` (Empty batch_outputs). Please use `Model.compile(..., run_eagerly=True)`, or `tf.config.run_functions_eagerly(True)` for more information of where went wrong, or file a issue/bug to `tf.keras`."
     ]
    }
   ],
   "source": [
    "for fold_num in tqdm(range(1, 5+1)):\n",
    "    time_counter = TimeUsed()\n",
    "    time_counter.start()\n",
    "    \n",
    "    # Record time for training\n",
    "    MODEL_PATH = f'{CURRENT_PATH}/results/models/{EXPERIMENT_NAME}/EfficientNetB0_None_FOLD_{fold_num}.h5'\n",
    "    RESULT_EVALUATE_PATH = os.path.join(CURRENT_PATH, \"results\", \"evaluate\", EXPERIMENT_NAME, \"EfficientNetB0_None\", \"Folds\", f\"fold_{fold_num}\")\n",
    "    Path(RESULT_EVALUATE_PATH).mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    test_dataset = Dataset(fold_num).get_test()\n",
    "    \n",
    "    best_model = Evaluate(MODEL_PATH)\n",
    "\n",
    "    best_model.get_best_threshold(\n",
    "        test_dataset=test_dataset,\n",
    "        save_best_thresholds=f\"{RESULT_EVALUATE_PATH}/best_thresholds.csv\",\n",
    "        save_200_thresholds=f\"{RESULT_EVALUATE_PATH}/f1_per_thresholds.csv\"\n",
    "    )\n",
    "    \n",
    "    with best_model:\n",
    "        f1_each_class = best_model.get_f1_scores(test_dataset)\n",
    "        pprint.pprint(f1_each_class)\n",
    "        df = pd.DataFrame(f1_each_class)\n",
    "        df.to_csv(f\"{RESULT_EVALUATE_PATH}/f1_scores.csv\", index=False)\n",
    "\n",
    "        precision_each_class = best_model.get_precision_scores(test_dataset, new_calculate=False)\n",
    "        pd.DataFrame(precision_each_class)\\\n",
    "            .to_csv(f\"{RESULT_EVALUATE_PATH}/precision.csv\", index=False)\n",
    "\n",
    "        recall_each_class = best_model.get_recall_scores(test_dataset, new_calculate=False)\n",
    "        pd.DataFrame(recall_each_class)\\\n",
    "            .to_csv(f\"{RESULT_EVALUATE_PATH}/recall.csv\", index=False)\n",
    "\n",
    "        # print(df)\n",
    "    \n",
    "    time_counter.stop_and_report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1190047-f702-4aac-bc5b-6a621165ab32",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
