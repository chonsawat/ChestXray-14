{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c7415ec7-92f0-4eb3-9f3b-31d9a9df0e51",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow_addons in /opt/conda/lib/python3.10/site-packages (0.19.0)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from tensorflow_addons) (21.3)\n",
      "Requirement already satisfied: typeguard>=2.7 in /opt/conda/lib/python3.10/site-packages (from tensorflow_addons) (3.0.2)\n",
      "Requirement already satisfied: typing-extensions>=4.4.0 in /opt/conda/lib/python3.10/site-packages (from typeguard>=2.7->tensorflow_addons) (4.5.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->tensorflow_addons) (3.0.9)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow_addons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d66c840d-74ed-4dce-8715-96701c28615d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/jovyan/ChestXray-14')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "67f814fb-1441-4f0d-a350-2721d6466e42",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-05 15:52:34.845322: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger, EarlyStopping, ReduceLROnPlateau, LearningRateScheduler, TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "711e4ac0-979b-41ff-a33a-78744a989705",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_PATH = \"/home/jovyan/ChestXray-14\"\n",
    "INPUT_PATH = f\"{ROOT_PATH}/dataset/ChestXray NIH\"\n",
    "\n",
    "LABELS = [\"Infiltration\", \"Atelectasis\",\"Effusion\", \"No Finding\"]\n",
    "\n",
    "EXPERIMENT_NAME = \"multiclass_classification_with_cross_entropy_loss_2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6bf97ed5-29bf-4f40-bc44-8dd34b3187a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset:\n",
    "    INPUT_PATH = INPUT_PATH\n",
    "    \n",
    "    def __init__(self, fold_num):\n",
    "        self.fold_num = fold_num\n",
    "    \n",
    "    def get_train(self):\n",
    "        filenames = tf.io.gfile.glob(f'{self.INPUT_PATH}/data/multiclass_dataset/folds/fold{self.fold_num}/train/*.tfrec')\n",
    "        dataset = get_dataset(filenames)\n",
    "        return dataset\n",
    "\n",
    "    def get_test(self):\n",
    "        filenames = tf.io.gfile.glob(f'{self.INPUT_PATH}/data/multiclass_dataset/folds/fold{self.fold_num}/test/*.tfrec')\n",
    "        dataset = get_dataset(filenames)\n",
    "        return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "636df3ad-fca2-4f11-8a51-bf4d36ae80f3",
   "metadata": {},
   "source": [
    "tf.keras.mixed_precision\n",
    "---\n",
    "make model train faster\n",
    "```python\n",
    "tf.keras.mixed_precision.global_policy()\n",
    "tf.keras.mixed_precision.set_global_policy('mixed_float16')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "87ea6bfa-7945-4dc3-8269-031a0c58ac5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Mixed precision compatibility check (mixed_float16): OK\n",
      "Your GPU will likely run quickly with dtype policy mixed_float16 as it has compute capability of at least 7.0. Your GPU: NVIDIA A100-SXM4-40GB MIG 2g.10gb, compute capability 8.0\n"
     ]
    }
   ],
   "source": [
    "tf.keras.mixed_precision.set_global_policy('mixed_float16')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cdc0ba5-7306-4e81-aaef-22dace23181a",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "439fd766-e37c-49f6-8caf-63bce64aec3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jovyan/ChestXray-14/experiments/MultiClass-Classification'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "CURRENT_PATH = os.path.abspath(\"\")\n",
    "CURRENT_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "216058d6-20e5-443e-b13d-a94a4a4b0914",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learning rate\n",
    "def lr_schedule(epoch, learning_rate):\n",
    "    tf.summary.scalar('learning rate', data=learning_rate, step=epoch)\n",
    "    return learning_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6d999200-df17-42e2-9df8-260023ed90e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "def get_callbacks(NAME, weight_option, fold_num=None):\n",
    "    log_dir = f\"{CURRENT_PATH}/logs/{EXPERIMENT_NAME}/{NAME}_{weight_option}_FOLD_{fold_num}\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "    \n",
    "    model_checkpoint_callback = ModelCheckpoint(f'results/models/{EXPERIMENT_NAME}/{NAME}_{weight_option}_FOLD_{fold_num}.h5', monitor='val_loss', mode='min', save_best_only=True)\n",
    "    early_stop_callback = EarlyStopping(monitor='val_loss', mode=\"min\", patience=20, verbose=1)\n",
    "    reduce_lr_callback = ReduceLROnPlateau(monitor='val_loss', mode=\"min\", factor=0.5, patience=3, verbose=1)\n",
    "    lr_logging_callback = LearningRateScheduler(lr_schedule)\n",
    "    \n",
    "    return model_checkpoint_callback, early_stop_callback, reduce_lr_callback, lr_logging_callback, tensorboard_callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "53c9d439-b8ef-4a49-b442-1a544fec7d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constant variables\n",
    "NAME = \"EfficientNetB0\"\n",
    "EPOCHS = 100\n",
    "weight_option = None # use `'imagenet'` or `None` only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "034c4668-751e-4aba-b2b6-5d71e0bb5980",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-05 15:52:38.058972: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-05 15:52:38.812472: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 8011 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB MIG 2g.10gb, pci bus id: 0000:31:00.0, compute capability: 8.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"multiclass_classification_with_cross_entropy_loss_2_FOLD_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " efficientnetb0 (Functional)  (None, 7, 7, 1280)       4049571   \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 62720)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               8028288   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 4)                 260       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 12,107,047\n",
      "Trainable params: 12,065,024\n",
      "Non-trainable params: 42,023\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-05 15:52:53.667630: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8100\n",
      "2023-04-05 15:52:54.624109: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-04-05 15:52:54.625214: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-04-05 15:52:54.625270: W tensorflow/stream_executor/gpu/asm_compiler.cc:80] Couldn't get ptxas version string: INTERNAL: Couldn't invoke ptxas --version\n",
      "2023-04-05 15:52:54.626419: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-04-05 15:52:54.626534: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] INTERNAL: Failed to launch ptxas\n",
      "Relying on driver to perform ptx compilation. \n",
      "Modify $PATH to customize ptxas location.\n",
      "This message will be only logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200/200 [==============================] - 40s 126ms/step - loss: 1.6356 - f1_score: 0.2645 - precision: 0.2567 - recall: 0.0328 - val_loss: 1.4083 - val_f1_score: 0.1040 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "200/200 [==============================] - 23s 113ms/step - loss: 1.5337 - f1_score: 0.2342 - precision: 0.2312 - recall: 0.0144 - val_loss: 1.3935 - val_f1_score: 0.1012 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "200/200 [==============================] - 22s 112ms/step - loss: 1.4008 - f1_score: 0.2454 - precision: 0.2656 - recall: 0.0053 - val_loss: 1.3858 - val_f1_score: 0.1040 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "200/200 [==============================] - 21s 105ms/step - loss: 1.3950 - f1_score: 0.2432 - precision: 0.3585 - recall: 0.0059 - val_loss: 1.3890 - val_f1_score: 0.1318 - val_precision: 0.3636 - val_recall: 0.0050 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "200/200 [==============================] - 21s 106ms/step - loss: 1.3903 - f1_score: 0.2578 - precision: 0.3226 - recall: 0.0031 - val_loss: 1.3873 - val_f1_score: 0.1314 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3890 - f1_score: 0.2353 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 6: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "200/200 [==============================] - 21s 106ms/step - loss: 1.3890 - f1_score: 0.2353 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.3910 - val_f1_score: 0.1850 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 5.0000e-04\n",
      "Epoch 7/100\n",
      "200/200 [==============================] - 22s 111ms/step - loss: 1.3866 - f1_score: 0.2029 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.3850 - val_f1_score: 0.2122 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 5.0000e-04\n",
      "Epoch 8/100\n",
      "200/200 [==============================] - 21s 107ms/step - loss: 1.3869 - f1_score: 0.2118 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.3860 - val_f1_score: 0.1857 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 5.0000e-04\n",
      "Epoch 9/100\n",
      "200/200 [==============================] - 22s 108ms/step - loss: 1.3858 - f1_score: 0.1904 - precision: 0.5000 - recall: 3.1250e-04 - val_loss: 1.4413 - val_f1_score: 0.1942 - val_precision: 0.2632 - val_recall: 0.0063 - lr: 5.0000e-04\n",
      "Epoch 10/100\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3858 - f1_score: 0.1924 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "200/200 [==============================] - 21s 106ms/step - loss: 1.3858 - f1_score: 0.1924 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.3891 - val_f1_score: 0.1572 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 2.5000e-04\n",
      "Epoch 11/100\n",
      "200/200 [==============================] - 21s 107ms/step - loss: 1.3822 - f1_score: 0.1853 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.3883 - val_f1_score: 0.1586 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 2.5000e-04\n",
      "Epoch 12/100\n",
      "200/200 [==============================] - 21s 107ms/step - loss: 1.3808 - f1_score: 0.1909 - precision: 0.5000 - recall: 3.1250e-04 - val_loss: 1.3867 - val_f1_score: 0.1603 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 2.5000e-04\n",
      "Epoch 13/100\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3807 - f1_score: 0.1945 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "200/200 [==============================] - 21s 106ms/step - loss: 1.3807 - f1_score: 0.1945 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.3869 - val_f1_score: 0.1866 - val_precision: 0.3333 - val_recall: 0.0012 - lr: 1.2500e-04\n",
      "Epoch 14/100\n",
      "200/200 [==============================] - 21s 106ms/step - loss: 1.3793 - f1_score: 0.2193 - precision: 0.1667 - recall: 3.1250e-04 - val_loss: 1.3882 - val_f1_score: 0.1639 - val_precision: 0.2857 - val_recall: 0.0025 - lr: 1.2500e-04\n",
      "Epoch 15/100\n",
      "200/200 [==============================] - 21s 106ms/step - loss: 1.3744 - f1_score: 0.1995 - precision: 0.8182 - recall: 0.0028 - val_loss: 1.3876 - val_f1_score: 0.1554 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 1.2500e-04\n",
      "Epoch 16/100\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3702 - f1_score: 0.2007 - precision: 0.6000 - recall: 0.0066\n",
      "Epoch 16: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "200/200 [==============================] - 21s 106ms/step - loss: 1.3702 - f1_score: 0.2007 - precision: 0.6000 - recall: 0.0066 - val_loss: 1.3918 - val_f1_score: 0.1770 - val_precision: 0.4167 - val_recall: 0.0063 - lr: 6.2500e-05\n",
      "Epoch 17/100\n",
      "200/200 [==============================] - 21s 106ms/step - loss: 1.3620 - f1_score: 0.2195 - precision: 0.5568 - recall: 0.0153 - val_loss: 1.3856 - val_f1_score: 0.1657 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 6.2500e-05\n",
      "Epoch 18/100\n",
      "200/200 [==============================] - 21s 106ms/step - loss: 1.3448 - f1_score: 0.2461 - precision: 0.5949 - recall: 0.0294 - val_loss: 1.3878 - val_f1_score: 0.1792 - val_precision: 0.2857 - val_recall: 0.0025 - lr: 6.2500e-05\n",
      "Epoch 19/100\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3212 - f1_score: 0.2549 - precision: 0.5858 - recall: 0.0491\n",
      "Epoch 19: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "200/200 [==============================] - 21s 106ms/step - loss: 1.3212 - f1_score: 0.2549 - precision: 0.5858 - recall: 0.0491 - val_loss: 1.3857 - val_f1_score: 0.1819 - val_precision: 0.6250 - val_recall: 0.0063 - lr: 3.1250e-05\n",
      "Epoch 20/100\n",
      "200/200 [==============================] - 21s 106ms/step - loss: 1.2747 - f1_score: 0.2938 - precision: 0.6545 - recall: 0.0894 - val_loss: 1.4056 - val_f1_score: 0.1758 - val_precision: 0.4390 - val_recall: 0.0225 - lr: 3.1250e-05\n",
      "Epoch 21/100\n",
      "200/200 [==============================] - 21s 106ms/step - loss: 1.2487 - f1_score: 0.3112 - precision: 0.6802 - recall: 0.1203 - val_loss: 1.4319 - val_f1_score: 0.1812 - val_precision: 0.4203 - val_recall: 0.0362 - lr: 3.1250e-05\n",
      "Epoch 22/100\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2083 - f1_score: 0.3275 - precision: 0.6756 - recall: 0.1653\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "200/200 [==============================] - 21s 106ms/step - loss: 1.2083 - f1_score: 0.3275 - precision: 0.6756 - recall: 0.1653 - val_loss: 1.4278 - val_f1_score: 0.1988 - val_precision: 0.3535 - val_recall: 0.0437 - lr: 1.5625e-05\n",
      "Epoch 23/100\n",
      "200/200 [==============================] - 21s 106ms/step - loss: 1.1574 - f1_score: 0.3510 - precision: 0.7309 - recall: 0.1969 - val_loss: 1.4213 - val_f1_score: 0.2027 - val_precision: 0.3678 - val_recall: 0.0400 - lr: 1.5625e-05\n",
      "Epoch 24/100\n",
      "200/200 [==============================] - 22s 108ms/step - loss: 1.1274 - f1_score: 0.3701 - precision: 0.7172 - recall: 0.2306 - val_loss: 1.4419 - val_f1_score: 0.2223 - val_precision: 0.3360 - val_recall: 0.0525 - lr: 1.5625e-05\n",
      "Epoch 25/100\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0942 - f1_score: 0.3988 - precision: 0.7286 - recall: 0.2500\n",
      "Epoch 25: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "200/200 [==============================] - 21s 106ms/step - loss: 1.0942 - f1_score: 0.3988 - precision: 0.7286 - recall: 0.2500 - val_loss: 1.4770 - val_f1_score: 0.2532 - val_precision: 0.3086 - val_recall: 0.0675 - lr: 7.8125e-06\n",
      "Epoch 26/100\n",
      "200/200 [==============================] - 21s 105ms/step - loss: 1.0716 - f1_score: 0.4087 - precision: 0.7403 - recall: 0.2744 - val_loss: 1.4808 - val_f1_score: 0.2726 - val_precision: 0.3351 - val_recall: 0.0800 - lr: 7.8125e-06\n",
      "Epoch 27/100\n",
      "200/200 [==============================] - 21s 105ms/step - loss: 1.0464 - f1_score: 0.4386 - precision: 0.7403 - recall: 0.2859 - val_loss: 1.4944 - val_f1_score: 0.2758 - val_precision: 0.3175 - val_recall: 0.0750 - lr: 7.8125e-06\n",
      "Epoch 27: early stopping\n",
      "===== ===== ===== ===== =====  Model Traninig for: 600.00 second(s) ===== ===== ===== ===== =====  \n",
      "\n",
      "\n",
      "Model: \"multiclass_classification_with_cross_entropy_loss_2_FOLD_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " efficientnetb0 (Functional)  (None, 7, 7, 1280)       4049571   \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 62720)             0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 128)               8028288   \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 4)                 260       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 12,107,047\n",
      "Trainable params: 12,065,024\n",
      "Non-trainable params: 42,023\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "200/200 [==============================] - 34s 125ms/step - loss: 1.6731 - f1_score: 0.2515 - precision_1: 0.2669 - recall_1: 0.0431 - val_loss: 1.4143 - val_f1_score: 0.1012 - val_precision_1: 0.0000e+00 - val_recall_1: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "200/200 [==============================] - 23s 113ms/step - loss: 1.4713 - f1_score: 0.2450 - precision_1: 0.2560 - recall_1: 0.0166 - val_loss: 1.3881 - val_f1_score: 0.1012 - val_precision_1: 0.0000e+00 - val_recall_1: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "200/200 [==============================] - 21s 106ms/step - loss: 1.4056 - f1_score: 0.2363 - precision_1: 0.3140 - recall_1: 0.0084 - val_loss: 1.3896 - val_f1_score: 0.0964 - val_precision_1: 0.0000e+00 - val_recall_1: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "200/200 [==============================] - 23s 113ms/step - loss: 1.3946 - f1_score: 0.1820 - precision_1: 0.2286 - recall_1: 0.0025 - val_loss: 1.3866 - val_f1_score: 0.1300 - val_precision_1: 0.0000e+00 - val_recall_1: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "200/200 [==============================] - 21s 107ms/step - loss: 1.3870 - f1_score: 0.2333 - precision_1: 0.0000e+00 - recall_1: 0.0000e+00 - val_loss: 1.3890 - val_f1_score: 0.1560 - val_precision_1: 0.0000e+00 - val_recall_1: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "200/200 [==============================] - 22s 107ms/step - loss: 1.3893 - f1_score: 0.2207 - precision_1: 0.4000 - recall_1: 0.0012 - val_loss: 1.4704 - val_f1_score: 0.1180 - val_precision_1: 0.3000 - val_recall_1: 0.0150 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4069 - f1_score: 0.2192 - precision_1: 0.2340 - recall_1: 0.0034\n",
      "Epoch 7: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "200/200 [==============================] - 21s 106ms/step - loss: 1.4069 - f1_score: 0.2192 - precision_1: 0.2340 - recall_1: 0.0034 - val_loss: 1.8694 - val_f1_score: 0.2109 - val_precision_1: 0.2513 - val_recall_1: 0.0587 - lr: 5.0000e-04\n",
      "Epoch 8/100\n",
      "200/200 [==============================] - 21s 107ms/step - loss: 1.3920 - f1_score: 0.2405 - precision_1: 0.2353 - recall_1: 0.0025 - val_loss: 1.3916 - val_f1_score: 0.1885 - val_precision_1: 0.3333 - val_recall_1: 0.0037 - lr: 5.0000e-04\n",
      "Epoch 9/100\n",
      "200/200 [==============================] - 22s 109ms/step - loss: 1.3874 - f1_score: 0.2303 - precision_1: 0.3333 - recall_1: 0.0012 - val_loss: 1.3993 - val_f1_score: 0.1799 - val_precision_1: 0.3750 - val_recall_1: 0.0075 - lr: 5.0000e-04\n",
      "Epoch 10/100\n",
      "200/200 [==============================] - 23s 113ms/step - loss: 1.3888 - f1_score: 0.2273 - precision_1: 0.5000 - recall_1: 3.1250e-04 - val_loss: 1.3828 - val_f1_score: 0.1860 - val_precision_1: 0.3333 - val_recall_1: 0.0012 - lr: 5.0000e-04\n",
      "Epoch 11/100\n",
      "200/200 [==============================] - 21s 107ms/step - loss: 1.3900 - f1_score: 0.2451 - precision_1: 0.1429 - recall_1: 6.2500e-04 - val_loss: 1.3996 - val_f1_score: 0.2051 - val_precision_1: 0.0000e+00 - val_recall_1: 0.0000e+00 - lr: 5.0000e-04\n",
      "Epoch 12/100\n",
      "200/200 [==============================] - 22s 108ms/step - loss: 1.3828 - f1_score: 0.2447 - precision_1: 0.2500 - recall_1: 6.2500e-04 - val_loss: 1.3895 - val_f1_score: 0.1991 - val_precision_1: 0.0000e+00 - val_recall_1: 0.0000e+00 - lr: 5.0000e-04\n",
      "Epoch 13/100\n",
      "200/200 [==============================] - 23s 115ms/step - loss: 1.3809 - f1_score: 0.2537 - precision_1: 0.0000e+00 - recall_1: 0.0000e+00 - val_loss: 1.3717 - val_f1_score: 0.2310 - val_precision_1: 0.0000e+00 - val_recall_1: 0.0000e+00 - lr: 5.0000e-04\n",
      "Epoch 14/100\n",
      "200/200 [==============================] - 23s 113ms/step - loss: 1.3667 - f1_score: 0.2696 - precision_1: 0.4375 - recall_1: 0.0022 - val_loss: 1.3634 - val_f1_score: 0.2495 - val_precision_1: 0.0000e+00 - val_recall_1: 0.0000e+00 - lr: 5.0000e-04\n",
      "Epoch 15/100\n",
      "200/200 [==============================] - 22s 108ms/step - loss: 1.3627 - f1_score: 0.2702 - precision_1: 0.4667 - recall_1: 0.0044 - val_loss: 1.3704 - val_f1_score: 0.2722 - val_precision_1: 0.3333 - val_recall_1: 0.0012 - lr: 5.0000e-04\n",
      "Epoch 16/100\n",
      "200/200 [==============================] - 22s 108ms/step - loss: 1.3542 - f1_score: 0.2792 - precision_1: 0.4800 - recall_1: 0.0113 - val_loss: 1.3676 - val_f1_score: 0.2517 - val_precision_1: 0.0000e+00 - val_recall_1: 0.0000e+00 - lr: 5.0000e-04\n",
      "Epoch 17/100\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3569 - f1_score: 0.2754 - precision_1: 0.4400 - recall_1: 0.0137\n",
      "Epoch 17: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "200/200 [==============================] - 21s 106ms/step - loss: 1.3569 - f1_score: 0.2754 - precision_1: 0.4400 - recall_1: 0.0137 - val_loss: 1.3811 - val_f1_score: 0.2493 - val_precision_1: 0.2000 - val_recall_1: 0.0037 - lr: 2.5000e-04\n",
      "Epoch 18/100\n",
      "200/200 [==============================] - 23s 113ms/step - loss: 1.3378 - f1_score: 0.2885 - precision_1: 0.4138 - recall_1: 0.0113 - val_loss: 1.3614 - val_f1_score: 0.2073 - val_precision_1: 0.1724 - val_recall_1: 0.0063 - lr: 2.5000e-04\n",
      "Epoch 19/100\n",
      "200/200 [==============================] - 21s 107ms/step - loss: 1.2846 - f1_score: 0.3173 - precision_1: 0.5411 - recall_1: 0.0597 - val_loss: 1.4023 - val_f1_score: 0.2082 - val_precision_1: 0.3580 - val_recall_1: 0.0362 - lr: 2.5000e-04\n",
      "Epoch 20/100\n",
      "200/200 [==============================] - 21s 106ms/step - loss: 1.2191 - f1_score: 0.3410 - precision_1: 0.5302 - recall_1: 0.1016 - val_loss: 1.4504 - val_f1_score: 0.2591 - val_precision_1: 0.5208 - val_recall_1: 0.0312 - lr: 2.5000e-04\n",
      "Epoch 21/100\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1568 - f1_score: 0.3772 - precision_1: 0.5658 - recall_1: 0.1344\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "200/200 [==============================] - 21s 107ms/step - loss: 1.1568 - f1_score: 0.3772 - precision_1: 0.5658 - recall_1: 0.1344 - val_loss: 1.5457 - val_f1_score: 0.2965 - val_precision_1: 0.3551 - val_recall_1: 0.0475 - lr: 1.2500e-04\n",
      "Epoch 22/100\n",
      "200/200 [==============================] - 21s 106ms/step - loss: 1.0237 - f1_score: 0.4532 - precision_1: 0.5684 - recall_1: 0.2325 - val_loss: 1.6790 - val_f1_score: 0.2796 - val_precision_1: 0.3399 - val_recall_1: 0.0650 - lr: 1.2500e-04\n",
      "Epoch 23/100\n",
      "200/200 [==============================] - 21s 106ms/step - loss: 0.9335 - f1_score: 0.4737 - precision_1: 0.5888 - recall_1: 0.3244 - val_loss: 1.8978 - val_f1_score: 0.3173 - val_precision_1: 0.3312 - val_recall_1: 0.1287 - lr: 1.2500e-04\n",
      "Epoch 24/100\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.8872 - f1_score: 0.4914 - precision_1: 0.6051 - recall_1: 0.3634\n",
      "Epoch 24: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "200/200 [==============================] - 21s 107ms/step - loss: 0.8872 - f1_score: 0.4914 - precision_1: 0.6051 - recall_1: 0.3634 - val_loss: 1.8626 - val_f1_score: 0.3076 - val_precision_1: 0.3140 - val_recall_1: 0.1287 - lr: 6.2500e-05\n",
      "Epoch 25/100\n",
      "200/200 [==============================] - 22s 108ms/step - loss: 0.8192 - f1_score: 0.5422 - precision_1: 0.6557 - recall_1: 0.4291 - val_loss: 1.8625 - val_f1_score: 0.3356 - val_precision_1: 0.3554 - val_recall_1: 0.1612 - lr: 6.2500e-05\n",
      "Epoch 26/100\n",
      "200/200 [==============================] - 22s 109ms/step - loss: 0.7580 - f1_score: 0.5705 - precision_1: 0.6682 - recall_1: 0.4872 - val_loss: 2.0829 - val_f1_score: 0.3248 - val_precision_1: 0.3502 - val_recall_1: 0.1813 - lr: 6.2500e-05\n",
      "Epoch 27/100\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.7352 - f1_score: 0.5994 - precision_1: 0.6899 - recall_1: 0.5172\n",
      "Epoch 27: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "200/200 [==============================] - 21s 106ms/step - loss: 0.7352 - f1_score: 0.5994 - precision_1: 0.6899 - recall_1: 0.5172 - val_loss: 2.0982 - val_f1_score: 0.3082 - val_precision_1: 0.3555 - val_recall_1: 0.2075 - lr: 3.1250e-05\n",
      "Epoch 28/100\n",
      "200/200 [==============================] - 22s 108ms/step - loss: 0.6841 - f1_score: 0.6119 - precision_1: 0.6985 - recall_1: 0.5422 - val_loss: 2.1336 - val_f1_score: 0.3328 - val_precision_1: 0.3548 - val_recall_1: 0.2062 - lr: 3.1250e-05\n",
      "Epoch 29/100\n",
      "200/200 [==============================] - 21s 107ms/step - loss: 0.6500 - f1_score: 0.6193 - precision_1: 0.7028 - recall_1: 0.5653 - val_loss: 2.2329 - val_f1_score: 0.3083 - val_precision_1: 0.3466 - val_recall_1: 0.2062 - lr: 3.1250e-05\n",
      "Epoch 30/100\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.6419 - f1_score: 0.6272 - precision_1: 0.7083 - recall_1: 0.5738\n",
      "Epoch 30: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "200/200 [==============================] - 22s 108ms/step - loss: 0.6419 - f1_score: 0.6272 - precision_1: 0.7083 - recall_1: 0.5738 - val_loss: 2.2350 - val_f1_score: 0.3198 - val_precision_1: 0.3482 - val_recall_1: 0.2237 - lr: 1.5625e-05\n",
      "Epoch 31/100\n",
      "200/200 [==============================] - 22s 108ms/step - loss: 0.6089 - f1_score: 0.6448 - precision_1: 0.7288 - recall_1: 0.6087 - val_loss: 2.2883 - val_f1_score: 0.3083 - val_precision_1: 0.3434 - val_recall_1: 0.2275 - lr: 1.5625e-05\n",
      "Epoch 32/100\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.6060 - f1_score: 0.6609 - precision_1: 0.7290 - recall_1: 0.6087 - val_loss: 2.3165 - val_f1_score: 0.3217 - val_precision_1: 0.3458 - val_recall_1: 0.2313 - lr: 1.5625e-05\n",
      "Epoch 33/100\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.5821 - f1_score: 0.6613 - precision_1: 0.7343 - recall_1: 0.6141\n",
      "Epoch 33: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "200/200 [==============================] - 21s 103ms/step - loss: 0.5821 - f1_score: 0.6613 - precision_1: 0.7343 - recall_1: 0.6141 - val_loss: 2.3650 - val_f1_score: 0.3196 - val_precision_1: 0.3430 - val_recall_1: 0.2362 - lr: 7.8125e-06\n",
      "Epoch 34/100\n",
      "200/200 [==============================] - 22s 108ms/step - loss: 0.5845 - f1_score: 0.6773 - precision_1: 0.7478 - recall_1: 0.6338 - val_loss: 2.3976 - val_f1_score: 0.3196 - val_precision_1: 0.3495 - val_recall_1: 0.2425 - lr: 7.8125e-06\n",
      "Epoch 35/100\n",
      "200/200 [==============================] - 22s 108ms/step - loss: 0.5774 - f1_score: 0.6656 - precision_1: 0.7331 - recall_1: 0.6197 - val_loss: 2.4169 - val_f1_score: 0.3203 - val_precision_1: 0.3494 - val_recall_1: 0.2450 - lr: 7.8125e-06\n",
      "Epoch 36/100\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.5687 - f1_score: 0.6781 - precision_1: 0.7483 - recall_1: 0.6400\n",
      "Epoch 36: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "200/200 [==============================] - 21s 105ms/step - loss: 0.5687 - f1_score: 0.6781 - precision_1: 0.7483 - recall_1: 0.6400 - val_loss: 2.4894 - val_f1_score: 0.3272 - val_precision_1: 0.3661 - val_recall_1: 0.2562 - lr: 3.9063e-06\n",
      "Epoch 37/100\n",
      "200/200 [==============================] - 21s 107ms/step - loss: 0.5694 - f1_score: 0.6676 - precision_1: 0.7342 - recall_1: 0.6353 - val_loss: 2.4928 - val_f1_score: 0.3280 - val_precision_1: 0.3569 - val_recall_1: 0.2525 - lr: 3.9063e-06\n",
      "Epoch 38/100\n",
      "200/200 [==============================] - 21s 102ms/step - loss: 0.5588 - f1_score: 0.6763 - precision_1: 0.7500 - recall_1: 0.6356 - val_loss: 2.5305 - val_f1_score: 0.3276 - val_precision_1: 0.3569 - val_recall_1: 0.2525 - lr: 3.9063e-06\n",
      "Epoch 38: early stopping\n",
      "===== ===== ===== ===== =====  Model Traninig for: 840.06 second(s) ===== ===== ===== ===== =====  \n",
      "\n",
      "\n",
      "Model: \"multiclass_classification_with_cross_entropy_loss_2_FOLD_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " efficientnetb0 (Functional)  (None, 7, 7, 1280)       4049571   \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 62720)             0         \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 128)               8028288   \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 4)                 260       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 12,107,047\n",
      "Trainable params: 12,065,024\n",
      "Non-trainable params: 42,023\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "200/200 [==============================] - 34s 122ms/step - loss: 1.5693 - f1_score: 0.2442 - precision_2: 0.2542 - recall_2: 0.0284 - val_loss: 1.3853 - val_f1_score: 0.1059 - val_precision_2: 0.0000e+00 - val_recall_2: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "200/200 [==============================] - 21s 105ms/step - loss: 1.3988 - f1_score: 0.2443 - precision_2: 0.1250 - recall_2: 9.3750e-04 - val_loss: 1.3856 - val_f1_score: 0.1024 - val_precision_2: 0.0000e+00 - val_recall_2: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "200/200 [==============================] - 21s 106ms/step - loss: 1.4830 - f1_score: 0.2475 - precision_2: 0.2935 - recall_2: 0.0169 - val_loss: 1.3865 - val_f1_score: 0.1060 - val_precision_2: 0.0000e+00 - val_recall_2: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3976 - f1_score: 0.2390 - precision_2: 0.3226 - recall_2: 0.0063\n",
      "Epoch 4: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "200/200 [==============================] - 21s 107ms/step - loss: 1.3976 - f1_score: 0.2390 - precision_2: 0.3226 - recall_2: 0.0063 - val_loss: 1.3895 - val_f1_score: 0.1020 - val_precision_2: 0.0000e+00 - val_recall_2: 0.0000e+00 - lr: 5.0000e-04\n",
      "Epoch 5/100\n",
      "200/200 [==============================] - 21s 106ms/step - loss: 1.3964 - f1_score: 0.2421 - precision_2: 0.1905 - recall_2: 0.0012 - val_loss: 1.3966 - val_f1_score: 0.1323 - val_precision_2: 0.4062 - val_recall_2: 0.0162 - lr: 5.0000e-04\n",
      "Epoch 6/100\n",
      "200/200 [==============================] - 21s 106ms/step - loss: 1.3898 - f1_score: 0.1511 - precision_2: 0.3750 - recall_2: 0.0019 - val_loss: 1.3869 - val_f1_score: 0.1048 - val_precision_2: 0.0000e+00 - val_recall_2: 0.0000e+00 - lr: 5.0000e-04\n",
      "Epoch 7/100\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3871 - f1_score: 0.1732 - precision_2: 1.0000 - recall_2: 3.1250e-04\n",
      "Epoch 7: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "200/200 [==============================] - 21s 105ms/step - loss: 1.3871 - f1_score: 0.1732 - precision_2: 1.0000 - recall_2: 3.1250e-04 - val_loss: 1.3924 - val_f1_score: 0.1039 - val_precision_2: 0.3684 - val_recall_2: 0.0088 - lr: 2.5000e-04\n",
      "Epoch 8/100\n",
      "200/200 [==============================] - 21s 106ms/step - loss: 1.3882 - f1_score: 0.1731 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00 - val_loss: 1.3856 - val_f1_score: 0.1634 - val_precision_2: 0.0000e+00 - val_recall_2: 0.0000e+00 - lr: 2.5000e-04\n",
      "Epoch 9/100\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 1.3838 - f1_score: 0.2117 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00 - val_loss: 1.3850 - val_f1_score: 0.0982 - val_precision_2: 0.0000e+00 - val_recall_2: 0.0000e+00 - lr: 2.5000e-04\n",
      "Epoch 10/100\n",
      "200/200 [==============================] - 21s 106ms/step - loss: 1.3840 - f1_score: 0.2318 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00 - val_loss: 1.3869 - val_f1_score: 0.1746 - val_precision_2: 1.0000 - val_recall_2: 0.0012 - lr: 2.5000e-04\n",
      "Epoch 11/100\n",
      "200/200 [==============================] - 21s 106ms/step - loss: 1.3839 - f1_score: 0.2618 - precision_2: 0.3333 - recall_2: 0.0012 - val_loss: 1.3865 - val_f1_score: 0.1611 - val_precision_2: 0.6667 - val_recall_2: 0.0025 - lr: 2.5000e-04\n",
      "Epoch 12/100\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3846 - f1_score: 0.2326 - precision_2: 0.1667 - recall_2: 3.1250e-04\n",
      "Epoch 12: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "200/200 [==============================] - 21s 105ms/step - loss: 1.3846 - f1_score: 0.2326 - precision_2: 0.1667 - recall_2: 3.1250e-04 - val_loss: 1.3853 - val_f1_score: 0.1514 - val_precision_2: 0.0000e+00 - val_recall_2: 0.0000e+00 - lr: 1.2500e-04\n",
      "Epoch 13/100\n",
      "200/200 [==============================] - 21s 105ms/step - loss: 1.3833 - f1_score: 0.2626 - precision_2: 0.4000 - recall_2: 6.2500e-04 - val_loss: 1.3851 - val_f1_score: 0.2575 - val_precision_2: 0.0000e+00 - val_recall_2: 0.0000e+00 - lr: 1.2500e-04\n",
      "Epoch 14/100\n",
      "200/200 [==============================] - 22s 111ms/step - loss: 1.3812 - f1_score: 0.2840 - precision_2: 0.5000 - recall_2: 6.2500e-04 - val_loss: 1.3845 - val_f1_score: 0.2773 - val_precision_2: 0.0000e+00 - val_recall_2: 0.0000e+00 - lr: 1.2500e-04\n",
      "Epoch 15/100\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 1.3792 - f1_score: 0.2603 - precision_2: 0.7778 - recall_2: 0.0022 - val_loss: 1.3840 - val_f1_score: 0.2411 - val_precision_2: 0.0000e+00 - val_recall_2: 0.0000e+00 - lr: 1.2500e-04\n",
      "Epoch 16/100\n",
      "200/200 [==============================] - 22s 111ms/step - loss: 1.3800 - f1_score: 0.2686 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00 - val_loss: 1.3834 - val_f1_score: 0.2474 - val_precision_2: 0.6667 - val_recall_2: 0.0025 - lr: 1.2500e-04\n",
      "Epoch 17/100\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 1.3825 - f1_score: 0.2607 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00 - val_loss: 1.3818 - val_f1_score: 0.2614 - val_precision_2: 0.0000e+00 - val_recall_2: 0.0000e+00 - lr: 1.2500e-04\n",
      "Epoch 18/100\n",
      "200/200 [==============================] - 22s 108ms/step - loss: 1.3767 - f1_score: 0.2656 - precision_2: 0.3333 - recall_2: 3.1250e-04 - val_loss: 1.3774 - val_f1_score: 0.2901 - val_precision_2: 0.0000e+00 - val_recall_2: 0.0000e+00 - lr: 1.2500e-04\n",
      "Epoch 19/100\n",
      "200/200 [==============================] - 21s 107ms/step - loss: 1.3712 - f1_score: 0.2830 - precision_2: 0.3571 - recall_2: 0.0016 - val_loss: 1.3711 - val_f1_score: 0.2494 - val_precision_2: 0.0000e+00 - val_recall_2: 0.0000e+00 - lr: 1.2500e-04\n",
      "Epoch 20/100\n",
      "200/200 [==============================] - 21s 104ms/step - loss: 1.3691 - f1_score: 0.2893 - precision_2: 0.2857 - recall_2: 0.0012 - val_loss: 1.3712 - val_f1_score: 0.2603 - val_precision_2: 0.0000e+00 - val_recall_2: 0.0000e+00 - lr: 1.2500e-04\n",
      "Epoch 21/100\n",
      "200/200 [==============================] - 22s 109ms/step - loss: 1.3607 - f1_score: 0.3114 - precision_2: 0.1429 - recall_2: 3.1250e-04 - val_loss: 1.3659 - val_f1_score: 0.2917 - val_precision_2: 1.0000 - val_recall_2: 0.0037 - lr: 1.2500e-04\n",
      "Epoch 22/100\n",
      "200/200 [==============================] - 21s 105ms/step - loss: 1.3575 - f1_score: 0.3131 - precision_2: 0.4286 - recall_2: 0.0084 - val_loss: 1.3687 - val_f1_score: 0.3153 - val_precision_2: 0.0000e+00 - val_recall_2: 0.0000e+00 - lr: 1.2500e-04\n",
      "Epoch 23/100\n",
      "200/200 [==============================] - 22s 111ms/step - loss: 1.3476 - f1_score: 0.2997 - precision_2: 0.4030 - recall_2: 0.0084 - val_loss: 1.3544 - val_f1_score: 0.3043 - val_precision_2: 0.3939 - val_recall_2: 0.0162 - lr: 1.2500e-04\n",
      "Epoch 24/100\n",
      "200/200 [==============================] - 22s 111ms/step - loss: 1.3274 - f1_score: 0.3239 - precision_2: 0.4161 - recall_2: 0.0209 - val_loss: 1.3365 - val_f1_score: 0.2684 - val_precision_2: 0.2857 - val_recall_2: 0.0025 - lr: 1.2500e-04\n",
      "Epoch 25/100\n",
      "200/200 [==============================] - 22s 111ms/step - loss: 1.3073 - f1_score: 0.3334 - precision_2: 0.5269 - recall_2: 0.0306 - val_loss: 1.3252 - val_f1_score: 0.3176 - val_precision_2: 0.5000 - val_recall_2: 0.0113 - lr: 1.2500e-04\n",
      "Epoch 26/100\n",
      "200/200 [==============================] - 22s 112ms/step - loss: 1.2702 - f1_score: 0.3411 - precision_2: 0.5487 - recall_2: 0.0722 - val_loss: 1.3160 - val_f1_score: 0.2828 - val_precision_2: 0.6000 - val_recall_2: 0.0225 - lr: 1.2500e-04\n",
      "Epoch 27/100\n",
      "200/200 [==============================] - 22s 107ms/step - loss: 1.2154 - f1_score: 0.3764 - precision_2: 0.5964 - recall_2: 0.1228 - val_loss: 1.3521 - val_f1_score: 0.3174 - val_precision_2: 0.4111 - val_recall_2: 0.0463 - lr: 1.2500e-04\n",
      "Epoch 28/100\n",
      "200/200 [==============================] - 21s 107ms/step - loss: 1.1529 - f1_score: 0.4059 - precision_2: 0.5952 - recall_2: 0.1622 - val_loss: 1.3576 - val_f1_score: 0.3136 - val_precision_2: 0.5104 - val_recall_2: 0.0613 - lr: 1.2500e-04\n",
      "Epoch 29/100\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0746 - f1_score: 0.4627 - precision_2: 0.6593 - recall_2: 0.2134\n",
      "Epoch 29: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "200/200 [==============================] - 22s 107ms/step - loss: 1.0746 - f1_score: 0.4627 - precision_2: 0.6593 - recall_2: 0.2134 - val_loss: 1.4685 - val_f1_score: 0.3264 - val_precision_2: 0.4470 - val_recall_2: 0.0737 - lr: 6.2500e-05\n",
      "Epoch 30/100\n",
      "200/200 [==============================] - 21s 107ms/step - loss: 0.9692 - f1_score: 0.5176 - precision_2: 0.6619 - recall_2: 0.3066 - val_loss: 1.5474 - val_f1_score: 0.2983 - val_precision_2: 0.3577 - val_recall_2: 0.1163 - lr: 6.2500e-05\n",
      "Epoch 31/100\n",
      "200/200 [==============================] - 21s 106ms/step - loss: 0.9061 - f1_score: 0.5446 - precision_2: 0.6726 - recall_2: 0.3647 - val_loss: 1.6790 - val_f1_score: 0.3163 - val_precision_2: 0.3860 - val_recall_2: 0.1375 - lr: 6.2500e-05\n",
      "Epoch 32/100\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.8517 - f1_score: 0.5682 - precision_2: 0.6757 - recall_2: 0.3984\n",
      "Epoch 32: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "200/200 [==============================] - 21s 106ms/step - loss: 0.8517 - f1_score: 0.5682 - precision_2: 0.6757 - recall_2: 0.3984 - val_loss: 1.7025 - val_f1_score: 0.2920 - val_precision_2: 0.3503 - val_recall_2: 0.1287 - lr: 3.1250e-05\n",
      "Epoch 33/100\n",
      "200/200 [==============================] - 21s 105ms/step - loss: 0.7495 - f1_score: 0.6129 - precision_2: 0.7123 - recall_2: 0.4650 - val_loss: 1.8591 - val_f1_score: 0.3089 - val_precision_2: 0.3546 - val_recall_2: 0.1600 - lr: 3.1250e-05\n",
      "Epoch 34/100\n",
      "200/200 [==============================] - 21s 105ms/step - loss: 0.7156 - f1_score: 0.6241 - precision_2: 0.7200 - recall_2: 0.4894 - val_loss: 1.9966 - val_f1_score: 0.2927 - val_precision_2: 0.3364 - val_recall_2: 0.1838 - lr: 3.1250e-05\n",
      "Epoch 35/100\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.6888 - f1_score: 0.6425 - precision_2: 0.7350 - recall_2: 0.5288\n",
      "Epoch 35: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "200/200 [==============================] - 21s 106ms/step - loss: 0.6888 - f1_score: 0.6425 - precision_2: 0.7350 - recall_2: 0.5288 - val_loss: 2.0676 - val_f1_score: 0.3013 - val_precision_2: 0.3229 - val_recall_2: 0.1937 - lr: 1.5625e-05\n",
      "Epoch 36/100\n",
      "200/200 [==============================] - 21s 106ms/step - loss: 0.6540 - f1_score: 0.6691 - precision_2: 0.7418 - recall_2: 0.5594 - val_loss: 2.1257 - val_f1_score: 0.2973 - val_precision_2: 0.3347 - val_recall_2: 0.2000 - lr: 1.5625e-05\n",
      "Epoch 37/100\n",
      "200/200 [==============================] - 21s 105ms/step - loss: 0.6429 - f1_score: 0.6633 - precision_2: 0.7436 - recall_2: 0.5619 - val_loss: 2.1875 - val_f1_score: 0.2959 - val_precision_2: 0.3280 - val_recall_2: 0.2050 - lr: 1.5625e-05\n",
      "Epoch 38/100\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.6094 - f1_score: 0.6909 - precision_2: 0.7600 - recall_2: 0.5956\n",
      "Epoch 38: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "200/200 [==============================] - 21s 105ms/step - loss: 0.6094 - f1_score: 0.6909 - precision_2: 0.7600 - recall_2: 0.5956 - val_loss: 2.1959 - val_f1_score: 0.3038 - val_precision_2: 0.3327 - val_recall_2: 0.2163 - lr: 7.8125e-06\n",
      "Epoch 39/100\n",
      "200/200 [==============================] - 21s 105ms/step - loss: 0.6007 - f1_score: 0.6825 - precision_2: 0.7546 - recall_2: 0.5997 - val_loss: 2.2445 - val_f1_score: 0.3083 - val_precision_2: 0.3346 - val_recall_2: 0.2225 - lr: 7.8125e-06\n",
      "Epoch 40/100\n",
      "200/200 [==============================] - 21s 106ms/step - loss: 0.5863 - f1_score: 0.6871 - precision_2: 0.7586 - recall_2: 0.6028 - val_loss: 2.2789 - val_f1_score: 0.3026 - val_precision_2: 0.3314 - val_recall_2: 0.2188 - lr: 7.8125e-06\n",
      "Epoch 41/100\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.5919 - f1_score: 0.6902 - precision_2: 0.7602 - recall_2: 0.6053\n",
      "Epoch 41: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "200/200 [==============================] - 21s 105ms/step - loss: 0.5919 - f1_score: 0.6902 - precision_2: 0.7602 - recall_2: 0.6053 - val_loss: 2.2979 - val_f1_score: 0.3034 - val_precision_2: 0.3277 - val_recall_2: 0.2163 - lr: 3.9063e-06\n",
      "Epoch 42/100\n",
      "200/200 [==============================] - 21s 105ms/step - loss: 0.5989 - f1_score: 0.6972 - precision_2: 0.7587 - recall_2: 0.6062 - val_loss: 2.3327 - val_f1_score: 0.3023 - val_precision_2: 0.3278 - val_recall_2: 0.2225 - lr: 3.9063e-06\n",
      "Epoch 43/100\n",
      "200/200 [==============================] - 21s 106ms/step - loss: 0.5837 - f1_score: 0.7095 - precision_2: 0.7738 - recall_2: 0.6275 - val_loss: 2.3392 - val_f1_score: 0.2944 - val_precision_2: 0.3291 - val_recall_2: 0.2288 - lr: 3.9063e-06\n",
      "Epoch 44/100\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.5937 - f1_score: 0.6831 - precision_2: 0.7471 - recall_2: 0.6066\n",
      "Epoch 44: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "200/200 [==============================] - 21s 105ms/step - loss: 0.5937 - f1_score: 0.6831 - precision_2: 0.7471 - recall_2: 0.6066 - val_loss: 2.3319 - val_f1_score: 0.2956 - val_precision_2: 0.3352 - val_recall_2: 0.2300 - lr: 1.9531e-06\n",
      "Epoch 45/100\n",
      "200/200 [==============================] - 21s 106ms/step - loss: 0.5834 - f1_score: 0.7060 - precision_2: 0.7645 - recall_2: 0.6209 - val_loss: 2.3512 - val_f1_score: 0.2961 - val_precision_2: 0.3321 - val_recall_2: 0.2288 - lr: 1.9531e-06\n",
      "Epoch 46/100\n",
      "200/200 [==============================] - 21s 105ms/step - loss: 0.5902 - f1_score: 0.6960 - precision_2: 0.7608 - recall_2: 0.6072 - val_loss: 2.3491 - val_f1_score: 0.3001 - val_precision_2: 0.3291 - val_recall_2: 0.2250 - lr: 1.9531e-06\n",
      "Epoch 46: early stopping\n",
      "===== ===== ===== ===== =====  Model Traninig for: 1003.48 second(s) ===== ===== ===== ===== =====  \n",
      "\n",
      "\n",
      "Model: \"multiclass_classification_with_cross_entropy_loss_2_FOLD_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " efficientnetb0 (Functional)  (None, 7, 7, 1280)       4049571   \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 62720)             0         \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 128)               8028288   \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 4)                 260       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 12,107,047\n",
      "Trainable params: 12,065,024\n",
      "Non-trainable params: 42,023\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "200/200 [==============================] - 33s 117ms/step - loss: 1.5686 - f1_score: 0.2411 - precision_3: 0.2569 - recall_3: 0.0322 - val_loss: 1.3878 - val_f1_score: 0.0964 - val_precision_3: 0.0000e+00 - val_recall_3: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "200/200 [==============================] - 21s 107ms/step - loss: 1.4230 - f1_score: 0.2409 - precision_3: 0.2737 - recall_3: 0.0081 - val_loss: 1.3992 - val_f1_score: 0.0914 - val_precision_3: 0.0000e+00 - val_recall_3: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "200/200 [==============================] - 21s 106ms/step - loss: 1.3981 - f1_score: 0.2048 - precision_3: 0.3529 - recall_3: 0.0056 - val_loss: 1.3894 - val_f1_score: 0.0914 - val_precision_3: 0.0000e+00 - val_recall_3: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "200/200 [==============================] - 22s 112ms/step - loss: 1.3890 - f1_score: 0.1581 - precision_3: 0.1429 - recall_3: 3.1250e-04 - val_loss: 1.3874 - val_f1_score: 0.0914 - val_precision_3: 0.0000e+00 - val_recall_3: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "200/200 [==============================] - 21s 105ms/step - loss: 1.3865 - f1_score: 0.1199 - precision_3: 0.0000e+00 - recall_3: 0.0000e+00 - val_loss: 1.3879 - val_f1_score: 0.0914 - val_precision_3: 0.0000e+00 - val_recall_3: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "200/200 [==============================] - 21s 107ms/step - loss: 1.3868 - f1_score: 0.1654 - precision_3: 0.0000e+00 - recall_3: 0.0000e+00 - val_loss: 1.3884 - val_f1_score: 0.0914 - val_precision_3: 0.0000e+00 - val_recall_3: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3866 - f1_score: 0.1199 - precision_3: 0.0000e+00 - recall_3: 0.0000e+00\n",
      "Epoch 7: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "200/200 [==============================] - 22s 108ms/step - loss: 1.3866 - f1_score: 0.1199 - precision_3: 0.0000e+00 - recall_3: 0.0000e+00 - val_loss: 1.3883 - val_f1_score: 0.0914 - val_precision_3: 0.0000e+00 - val_recall_3: 0.0000e+00 - lr: 5.0000e-04\n",
      "Epoch 8/100\n",
      "200/200 [==============================] - 22s 108ms/step - loss: 1.3859 - f1_score: 0.1253 - precision_3: 0.5000 - recall_3: 6.2500e-04 - val_loss: 1.3881 - val_f1_score: 0.0914 - val_precision_3: 0.0000e+00 - val_recall_3: 0.0000e+00 - lr: 5.0000e-04\n",
      "Epoch 9/100\n",
      "200/200 [==============================] - 23s 116ms/step - loss: 1.3873 - f1_score: 0.1135 - precision_3: 0.0000e+00 - recall_3: 0.0000e+00 - val_loss: 1.3872 - val_f1_score: 0.1063 - val_precision_3: 0.0000e+00 - val_recall_3: 0.0000e+00 - lr: 5.0000e-04\n",
      "Epoch 10/100\n",
      "200/200 [==============================] - 22s 111ms/step - loss: 1.3886 - f1_score: 0.1194 - precision_3: 0.2000 - recall_3: 3.1250e-04 - val_loss: 1.3880 - val_f1_score: 0.0914 - val_precision_3: 0.0000e+00 - val_recall_3: 0.0000e+00 - lr: 5.0000e-04\n",
      "Epoch 11/100\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 1.3856 - f1_score: 0.1093 - precision_3: 0.0000e+00 - recall_3: 0.0000e+00 - val_loss: 1.3883 - val_f1_score: 0.0914 - val_precision_3: 0.0000e+00 - val_recall_3: 0.0000e+00 - lr: 5.0000e-04\n",
      "Epoch 12/100\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3861 - f1_score: 0.1098 - precision_3: 0.5000 - recall_3: 3.1250e-04\n",
      "Epoch 12: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "200/200 [==============================] - 22s 109ms/step - loss: 1.3861 - f1_score: 0.1098 - precision_3: 0.5000 - recall_3: 3.1250e-04 - val_loss: 1.3883 - val_f1_score: 0.0914 - val_precision_3: 0.0000e+00 - val_recall_3: 0.0000e+00 - lr: 2.5000e-04\n",
      "Epoch 13/100\n",
      "200/200 [==============================] - 22s 107ms/step - loss: 1.3861 - f1_score: 0.1143 - precision_3: 0.2500 - recall_3: 3.1250e-04 - val_loss: 1.3880 - val_f1_score: 0.0914 - val_precision_3: 0.0000e+00 - val_recall_3: 0.0000e+00 - lr: 2.5000e-04\n",
      "Epoch 14/100\n",
      "200/200 [==============================] - 21s 105ms/step - loss: 1.3860 - f1_score: 0.1291 - precision_3: 0.3333 - recall_3: 9.3750e-04 - val_loss: 1.3874 - val_f1_score: 0.1167 - val_precision_3: 0.0000e+00 - val_recall_3: 0.0000e+00 - lr: 2.5000e-04\n",
      "Epoch 15/100\n",
      "200/200 [==============================] - 23s 113ms/step - loss: 1.3863 - f1_score: 0.1365 - precision_3: 0.0000e+00 - recall_3: 0.0000e+00 - val_loss: 1.3840 - val_f1_score: 0.1372 - val_precision_3: 1.0000 - val_recall_3: 0.0025 - lr: 2.5000e-04\n",
      "Epoch 16/100\n",
      "200/200 [==============================] - 21s 107ms/step - loss: 1.3858 - f1_score: 0.1264 - precision_3: 0.0000e+00 - recall_3: 0.0000e+00 - val_loss: 1.3875 - val_f1_score: 0.1207 - val_precision_3: 1.0000 - val_recall_3: 0.0025 - lr: 2.5000e-04\n",
      "Epoch 17/100\n",
      "200/200 [==============================] - 21s 107ms/step - loss: 1.3868 - f1_score: 0.1102 - precision_3: 0.0000e+00 - recall_3: 0.0000e+00 - val_loss: 1.3884 - val_f1_score: 0.0915 - val_precision_3: 0.0000e+00 - val_recall_3: 0.0000e+00 - lr: 2.5000e-04\n",
      "Epoch 18/100\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3876 - f1_score: 0.1343 - precision_3: 0.3333 - recall_3: 6.2500e-04\n",
      "Epoch 18: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "200/200 [==============================] - 21s 107ms/step - loss: 1.3876 - f1_score: 0.1343 - precision_3: 0.3333 - recall_3: 6.2500e-04 - val_loss: 1.3867 - val_f1_score: 0.1319 - val_precision_3: 0.4167 - val_recall_3: 0.0063 - lr: 1.2500e-04\n",
      "Epoch 19/100\n",
      "200/200 [==============================] - 22s 108ms/step - loss: 1.3859 - f1_score: 0.1329 - precision_3: 0.3333 - recall_3: 3.1250e-04 - val_loss: 1.3869 - val_f1_score: 0.1105 - val_precision_3: 0.4545 - val_recall_3: 0.0063 - lr: 1.2500e-04\n",
      "Epoch 20/100\n",
      "200/200 [==============================] - 22s 107ms/step - loss: 1.3856 - f1_score: 0.1335 - precision_3: 0.0000e+00 - recall_3: 0.0000e+00 - val_loss: 1.3880 - val_f1_score: 0.1105 - val_precision_3: 0.4545 - val_recall_3: 0.0063 - lr: 1.2500e-04\n",
      "Epoch 21/100\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3856 - f1_score: 0.1349 - precision_3: 0.0000e+00 - recall_3: 0.0000e+00\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "200/200 [==============================] - 22s 108ms/step - loss: 1.3856 - f1_score: 0.1349 - precision_3: 0.0000e+00 - recall_3: 0.0000e+00 - val_loss: 1.3924 - val_f1_score: 0.1216 - val_precision_3: 0.4500 - val_recall_3: 0.0113 - lr: 6.2500e-05\n",
      "Epoch 22/100\n",
      "200/200 [==============================] - 21s 106ms/step - loss: 1.3846 - f1_score: 0.1450 - precision_3: 0.0000e+00 - recall_3: 0.0000e+00 - val_loss: 1.3926 - val_f1_score: 0.1246 - val_precision_3: 0.4500 - val_recall_3: 0.0113 - lr: 6.2500e-05\n",
      "Epoch 23/100\n",
      "200/200 [==============================] - 21s 104ms/step - loss: 1.3840 - f1_score: 0.1404 - precision_3: 1.0000 - recall_3: 3.1250e-04 - val_loss: 1.3943 - val_f1_score: 0.1209 - val_precision_3: 0.4211 - val_recall_3: 0.0100 - lr: 6.2500e-05\n",
      "Epoch 24/100\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3831 - f1_score: 0.1408 - precision_3: 0.4000 - recall_3: 6.2500e-04\n",
      "Epoch 24: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "200/200 [==============================] - 21s 105ms/step - loss: 1.3831 - f1_score: 0.1408 - precision_3: 0.4000 - recall_3: 6.2500e-04 - val_loss: 1.3912 - val_f1_score: 0.1224 - val_precision_3: 0.4706 - val_recall_3: 0.0100 - lr: 3.1250e-05\n",
      "Epoch 25/100\n",
      "200/200 [==============================] - 22s 108ms/step - loss: 1.3829 - f1_score: 0.1412 - precision_3: 0.5000 - recall_3: 0.0012 - val_loss: 1.3923 - val_f1_score: 0.1146 - val_precision_3: 0.4375 - val_recall_3: 0.0088 - lr: 3.1250e-05\n",
      "Epoch 26/100\n",
      "200/200 [==============================] - 21s 106ms/step - loss: 1.3845 - f1_score: 0.1412 - precision_3: 0.5000 - recall_3: 6.2500e-04 - val_loss: 1.3909 - val_f1_score: 0.1222 - val_precision_3: 0.4118 - val_recall_3: 0.0088 - lr: 3.1250e-05\n",
      "Epoch 27/100\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3815 - f1_score: 0.1460 - precision_3: 1.0000 - recall_3: 9.3750e-04\n",
      "Epoch 27: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "200/200 [==============================] - 22s 107ms/step - loss: 1.3815 - f1_score: 0.1460 - precision_3: 1.0000 - recall_3: 9.3750e-04 - val_loss: 1.4001 - val_f1_score: 0.1234 - val_precision_3: 0.4091 - val_recall_3: 0.0113 - lr: 1.5625e-05\n",
      "Epoch 28/100\n",
      "200/200 [==============================] - 21s 103ms/step - loss: 1.3829 - f1_score: 0.1424 - precision_3: 0.6000 - recall_3: 9.3750e-04 - val_loss: 1.3931 - val_f1_score: 0.1190 - val_precision_3: 0.4118 - val_recall_3: 0.0088 - lr: 1.5625e-05\n",
      "Epoch 29/100\n",
      "200/200 [==============================] - 21s 106ms/step - loss: 1.3835 - f1_score: 0.1434 - precision_3: 0.5000 - recall_3: 9.3750e-04 - val_loss: 1.3941 - val_f1_score: 0.1208 - val_precision_3: 0.3889 - val_recall_3: 0.0088 - lr: 1.5625e-05\n",
      "Epoch 30/100\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3817 - f1_score: 0.1460 - precision_3: 0.8750 - recall_3: 0.0022\n",
      "Epoch 30: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "200/200 [==============================] - 22s 107ms/step - loss: 1.3817 - f1_score: 0.1460 - precision_3: 0.8750 - recall_3: 0.0022 - val_loss: 1.3932 - val_f1_score: 0.1224 - val_precision_3: 0.3889 - val_recall_3: 0.0088 - lr: 7.8125e-06\n",
      "Epoch 31/100\n",
      "200/200 [==============================] - 21s 105ms/step - loss: 1.3822 - f1_score: 0.1488 - precision_3: 0.5000 - recall_3: 0.0012 - val_loss: 1.3954 - val_f1_score: 0.1221 - val_precision_3: 0.3889 - val_recall_3: 0.0088 - lr: 7.8125e-06\n",
      "Epoch 32/100\n",
      "200/200 [==============================] - 21s 106ms/step - loss: 1.3825 - f1_score: 0.1425 - precision_3: 0.5556 - recall_3: 0.0016 - val_loss: 1.3951 - val_f1_score: 0.1222 - val_precision_3: 0.3889 - val_recall_3: 0.0088 - lr: 7.8125e-06\n",
      "Epoch 33/100\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3824 - f1_score: 0.1465 - precision_3: 0.7143 - recall_3: 0.0016\n",
      "Epoch 33: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "200/200 [==============================] - 21s 105ms/step - loss: 1.3824 - f1_score: 0.1465 - precision_3: 0.7143 - recall_3: 0.0016 - val_loss: 1.3946 - val_f1_score: 0.1248 - val_precision_3: 0.3889 - val_recall_3: 0.0088 - lr: 3.9063e-06\n",
      "Epoch 34/100\n",
      "200/200 [==============================] - 21s 106ms/step - loss: 1.3794 - f1_score: 0.1435 - precision_3: 0.8000 - recall_3: 0.0037 - val_loss: 1.3969 - val_f1_score: 0.1221 - val_precision_3: 0.3684 - val_recall_3: 0.0088 - lr: 3.9063e-06\n",
      "Epoch 35/100\n",
      "200/200 [==============================] - 21s 104ms/step - loss: 1.3807 - f1_score: 0.1512 - precision_3: 0.8125 - recall_3: 0.0041 - val_loss: 1.3966 - val_f1_score: 0.1221 - val_precision_3: 0.3684 - val_recall_3: 0.0088 - lr: 3.9063e-06\n",
      "Epoch 35: early stopping\n",
      "===== ===== ===== ===== =====  Model Traninig for: 768.20 second(s) ===== ===== ===== ===== =====  \n",
      "\n",
      "\n",
      "Model: \"multiclass_classification_with_cross_entropy_loss_2_FOLD_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " efficientnetb0 (Functional)  (None, 7, 7, 1280)       4049571   \n",
      "                                                                 \n",
      " flatten_4 (Flatten)         (None, 62720)             0         \n",
      "                                                                 \n",
      " dense_20 (Dense)            (None, 128)               8028288   \n",
      "                                                                 \n",
      " dropout_8 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_21 (Dense)            (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_22 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " dropout_9 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_23 (Dense)            (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_24 (Dense)            (None, 4)                 260       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 12,107,047\n",
      "Trainable params: 12,065,024\n",
      "Non-trainable params: 42,023\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "200/200 [==============================] - 35s 123ms/step - loss: 1.6365 - f1_score: 0.2565 - precision_4: 0.2584 - recall_4: 0.0434 - val_loss: 1.3968 - val_f1_score: 0.0972 - val_precision_4: 0.0000e+00 - val_recall_4: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "200/200 [==============================] - 22s 111ms/step - loss: 1.4281 - f1_score: 0.2435 - precision_4: 0.2205 - recall_4: 0.0088 - val_loss: 1.3861 - val_f1_score: 0.1308 - val_precision_4: 0.0000e+00 - val_recall_4: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "200/200 [==============================] - 21s 106ms/step - loss: 1.3957 - f1_score: 0.2247 - precision_4: 0.2258 - recall_4: 0.0022 - val_loss: 1.3885 - val_f1_score: 0.0964 - val_precision_4: 0.0000e+00 - val_recall_4: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "200/200 [==============================] - 22s 108ms/step - loss: 1.3876 - f1_score: 0.2444 - precision_4: 0.3333 - recall_4: 0.0016 - val_loss: 1.4023 - val_f1_score: 0.1782 - val_precision_4: 0.0000e+00 - val_recall_4: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4298 - f1_score: 0.2410 - precision_4: 0.2707 - recall_4: 0.0113\n",
      "Epoch 5: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "200/200 [==============================] - 22s 107ms/step - loss: 1.4298 - f1_score: 0.2410 - precision_4: 0.2707 - recall_4: 0.0113 - val_loss: 7.3780 - val_f1_score: 0.0976 - val_precision_4: 0.2464 - val_recall_4: 0.2375 - lr: 5.0000e-04\n",
      "Epoch 6/100\n",
      "200/200 [==============================] - 21s 106ms/step - loss: 1.3980 - f1_score: 0.2510 - precision_4: 0.2424 - recall_4: 0.0025 - val_loss: 1.3948 - val_f1_score: 0.1234 - val_precision_4: 0.3333 - val_recall_4: 0.0025 - lr: 5.0000e-04\n",
      "Epoch 7/100\n",
      "200/200 [==============================] - 21s 106ms/step - loss: 1.3908 - f1_score: 0.2056 - precision_4: 0.5000 - recall_4: 9.3750e-04 - val_loss: 1.3905 - val_f1_score: 0.1151 - val_precision_4: 0.0000e+00 - val_recall_4: 0.0000e+00 - lr: 5.0000e-04\n",
      "Epoch 8/100\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.3910 - f1_score: 0.2208 - precision_4: 0.2222 - recall_4: 6.2500e-04\n",
      "Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "200/200 [==============================] - 21s 107ms/step - loss: 1.3910 - f1_score: 0.2208 - precision_4: 0.2222 - recall_4: 6.2500e-04 - val_loss: 1.3891 - val_f1_score: 0.1205 - val_precision_4: 0.5000 - val_recall_4: 0.0012 - lr: 2.5000e-04\n",
      "Epoch 9/100\n",
      "200/200 [==============================] - 21s 105ms/step - loss: 1.3865 - f1_score: 0.1985 - precision_4: 0.3333 - recall_4: 3.1250e-04 - val_loss: 1.3868 - val_f1_score: 0.1468 - val_precision_4: 0.0000e+00 - val_recall_4: 0.0000e+00 - lr: 2.5000e-04\n",
      "Epoch 10/100\n",
      "200/200 [==============================] - 23s 113ms/step - loss: 1.3866 - f1_score: 0.2289 - precision_4: 0.2857 - recall_4: 6.2500e-04 - val_loss: 1.3848 - val_f1_score: 0.1606 - val_precision_4: 0.0000e+00 - val_recall_4: 0.0000e+00 - lr: 2.5000e-04\n",
      "Epoch 11/100\n",
      "200/200 [==============================] - 22s 108ms/step - loss: 1.3870 - f1_score: 0.2512 - precision_4: 0.2000 - recall_4: 3.1250e-04 - val_loss: 1.3855 - val_f1_score: 0.1760 - val_precision_4: 0.0000e+00 - val_recall_4: 0.0000e+00 - lr: 2.5000e-04\n",
      "Epoch 12/100\n",
      "200/200 [==============================] - 21s 106ms/step - loss: 1.3850 - f1_score: 0.2208 - precision_4: 1.0000 - recall_4: 6.2500e-04 - val_loss: 1.3860 - val_f1_score: 0.1582 - val_precision_4: 0.0000e+00 - val_recall_4: 0.0000e+00 - lr: 2.5000e-04\n",
      "Epoch 13/100\n",
      "200/200 [==============================] - 23s 115ms/step - loss: 1.3819 - f1_score: 0.2352 - precision_4: 1.0000 - recall_4: 3.1250e-04 - val_loss: 1.3813 - val_f1_score: 0.2327 - val_precision_4: 1.0000 - val_recall_4: 0.0012 - lr: 2.5000e-04\n",
      "Epoch 14/100\n",
      "200/200 [==============================] - 21s 106ms/step - loss: 1.3825 - f1_score: 0.2399 - precision_4: 0.5000 - recall_4: 3.1250e-04 - val_loss: 1.3883 - val_f1_score: 0.2302 - val_precision_4: 0.0000e+00 - val_recall_4: 0.0000e+00 - lr: 2.5000e-04\n",
      "Epoch 15/100\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 1.3814 - f1_score: 0.2468 - precision_4: 0.2857 - recall_4: 6.2500e-04 - val_loss: 1.3808 - val_f1_score: 0.2000 - val_precision_4: 0.0000e+00 - val_recall_4: 0.0000e+00 - lr: 2.5000e-04\n",
      "Epoch 16/100\n",
      "200/200 [==============================] - 21s 106ms/step - loss: 1.3798 - f1_score: 0.2584 - precision_4: 0.2500 - recall_4: 6.2500e-04 - val_loss: 1.3873 - val_f1_score: 0.1982 - val_precision_4: 0.0000e+00 - val_recall_4: 0.0000e+00 - lr: 2.5000e-04\n",
      "Epoch 17/100\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 1.3787 - f1_score: 0.2369 - precision_4: 0.5000 - recall_4: 0.0012 - val_loss: 1.3670 - val_f1_score: 0.2794 - val_precision_4: 0.0000e+00 - val_recall_4: 0.0000e+00 - lr: 2.5000e-04\n",
      "Epoch 18/100\n",
      "200/200 [==============================] - 21s 106ms/step - loss: 1.3716 - f1_score: 0.2621 - precision_4: 0.1765 - recall_4: 9.3750e-04 - val_loss: 1.4069 - val_f1_score: 0.1201 - val_precision_4: 0.0000e+00 - val_recall_4: 0.0000e+00 - lr: 2.5000e-04\n",
      "Epoch 19/100\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 1.3599 - f1_score: 0.2475 - precision_4: 0.5072 - recall_4: 0.0109 - val_loss: 1.3585 - val_f1_score: 0.2163 - val_precision_4: 0.0000e+00 - val_recall_4: 0.0000e+00 - lr: 2.5000e-04\n",
      "Epoch 20/100\n",
      "200/200 [==============================] - 22s 111ms/step - loss: 1.3434 - f1_score: 0.2628 - precision_4: 0.4400 - recall_4: 0.0206 - val_loss: 1.3454 - val_f1_score: 0.2392 - val_precision_4: 0.0000e+00 - val_recall_4: 0.0000e+00 - lr: 2.5000e-04\n",
      "Epoch 21/100\n",
      "200/200 [==============================] - 21s 106ms/step - loss: 1.3324 - f1_score: 0.2937 - precision_4: 0.5547 - recall_4: 0.0444 - val_loss: 1.3697 - val_f1_score: 0.2297 - val_precision_4: 1.0000 - val_recall_4: 0.0012 - lr: 2.5000e-04\n",
      "Epoch 22/100\n",
      "200/200 [==============================] - 21s 106ms/step - loss: 1.3041 - f1_score: 0.2988 - precision_4: 0.5582 - recall_4: 0.0659 - val_loss: 1.4473 - val_f1_score: 0.1081 - val_precision_4: 0.4000 - val_recall_4: 0.0025 - lr: 2.5000e-04\n",
      "Epoch 23/100\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2715 - f1_score: 0.3405 - precision_4: 0.5986 - recall_4: 0.1034\n",
      "Epoch 23: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "200/200 [==============================] - 22s 108ms/step - loss: 1.2715 - f1_score: 0.3405 - precision_4: 0.5986 - recall_4: 0.1034 - val_loss: 1.4231 - val_f1_score: 0.2213 - val_precision_4: 0.4340 - val_recall_4: 0.0288 - lr: 1.2500e-04\n",
      "Epoch 24/100\n",
      "200/200 [==============================] - 22s 107ms/step - loss: 1.1593 - f1_score: 0.4124 - precision_4: 0.6868 - recall_4: 0.1988 - val_loss: 1.4203 - val_f1_score: 0.2759 - val_precision_4: 0.4175 - val_recall_4: 0.1013 - lr: 1.2500e-04\n",
      "Epoch 25/100\n",
      "200/200 [==============================] - 21s 105ms/step - loss: 1.0683 - f1_score: 0.4450 - precision_4: 0.7036 - recall_4: 0.2700 - val_loss: 1.5271 - val_f1_score: 0.2873 - val_precision_4: 0.4177 - val_recall_4: 0.1238 - lr: 1.2500e-04\n",
      "Epoch 26/100\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9724 - f1_score: 0.5143 - precision_4: 0.7261 - recall_4: 0.3272\n",
      "Epoch 26: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "200/200 [==============================] - 21s 106ms/step - loss: 0.9724 - f1_score: 0.5143 - precision_4: 0.7261 - recall_4: 0.3272 - val_loss: 1.6630 - val_f1_score: 0.3372 - val_precision_4: 0.4074 - val_recall_4: 0.1375 - lr: 6.2500e-05\n",
      "Epoch 27/100\n",
      "200/200 [==============================] - 21s 105ms/step - loss: 0.8557 - f1_score: 0.5907 - precision_4: 0.7824 - recall_4: 0.4147 - val_loss: 1.6748 - val_f1_score: 0.3487 - val_precision_4: 0.3834 - val_recall_4: 0.1500 - lr: 6.2500e-05\n",
      "Epoch 28/100\n",
      "200/200 [==============================] - 21s 107ms/step - loss: 0.7563 - f1_score: 0.6593 - precision_4: 0.7934 - recall_4: 0.5184 - val_loss: 1.7831 - val_f1_score: 0.3505 - val_precision_4: 0.3886 - val_recall_4: 0.2050 - lr: 6.2500e-05\n",
      "Epoch 29/100\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.6950 - f1_score: 0.6987 - precision_4: 0.7965 - recall_4: 0.5809\n",
      "Epoch 29: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "200/200 [==============================] - 21s 107ms/step - loss: 0.6950 - f1_score: 0.6987 - precision_4: 0.7965 - recall_4: 0.5809 - val_loss: 1.9495 - val_f1_score: 0.3646 - val_precision_4: 0.3900 - val_recall_4: 0.2837 - lr: 3.1250e-05\n",
      "Epoch 30/100\n",
      "200/200 [==============================] - 21s 106ms/step - loss: 0.6138 - f1_score: 0.7357 - precision_4: 0.8266 - recall_4: 0.6494 - val_loss: 2.0780 - val_f1_score: 0.3682 - val_precision_4: 0.3990 - val_recall_4: 0.2962 - lr: 3.1250e-05\n",
      "Epoch 31/100\n",
      "200/200 [==============================] - 22s 108ms/step - loss: 0.5324 - f1_score: 0.7725 - precision_4: 0.8466 - recall_4: 0.6969 - val_loss: 2.4229 - val_f1_score: 0.3710 - val_precision_4: 0.3843 - val_recall_4: 0.3113 - lr: 3.1250e-05\n",
      "Epoch 32/100\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.5017 - f1_score: 0.7872 - precision_4: 0.8408 - recall_4: 0.7309\n",
      "Epoch 32: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "200/200 [==============================] - 21s 107ms/step - loss: 0.5017 - f1_score: 0.7872 - precision_4: 0.8408 - recall_4: 0.7309 - val_loss: 2.3669 - val_f1_score: 0.3542 - val_precision_4: 0.3750 - val_recall_4: 0.3150 - lr: 1.5625e-05\n",
      "Epoch 33/100\n",
      "200/200 [==============================] - 21s 105ms/step - loss: 0.4571 - f1_score: 0.8159 - precision_4: 0.8689 - recall_4: 0.7619 - val_loss: 2.5865 - val_f1_score: 0.3576 - val_precision_4: 0.3736 - val_recall_4: 0.3288 - lr: 1.5625e-05\n",
      "Epoch 34/100\n",
      "200/200 [==============================] - 21s 105ms/step - loss: 0.4114 - f1_score: 0.8340 - precision_4: 0.8817 - recall_4: 0.7828 - val_loss: 2.7941 - val_f1_score: 0.3527 - val_precision_4: 0.3689 - val_recall_4: 0.3325 - lr: 1.5625e-05\n",
      "Epoch 35/100\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.4022 - f1_score: 0.8409 - precision_4: 0.8825 - recall_4: 0.7956\n",
      "Epoch 35: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "200/200 [==============================] - 21s 106ms/step - loss: 0.4022 - f1_score: 0.8409 - precision_4: 0.8825 - recall_4: 0.7956 - val_loss: 2.9309 - val_f1_score: 0.3400 - val_precision_4: 0.3497 - val_recall_4: 0.3212 - lr: 7.8125e-06\n",
      "Epoch 36/100\n",
      "200/200 [==============================] - 22s 107ms/step - loss: 0.3798 - f1_score: 0.8502 - precision_4: 0.8956 - recall_4: 0.8066 - val_loss: 2.8613 - val_f1_score: 0.3479 - val_precision_4: 0.3539 - val_recall_4: 0.3225 - lr: 7.8125e-06\n",
      "Epoch 37/100\n",
      "200/200 [==============================] - 21s 106ms/step - loss: 0.3689 - f1_score: 0.8531 - precision_4: 0.9045 - recall_4: 0.8112 - val_loss: 2.9143 - val_f1_score: 0.3429 - val_precision_4: 0.3563 - val_recall_4: 0.3300 - lr: 7.8125e-06\n",
      "Epoch 38/100\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.3636 - f1_score: 0.8591 - precision_4: 0.9123 - recall_4: 0.8194\n",
      "Epoch 38: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "200/200 [==============================] - 21s 106ms/step - loss: 0.3636 - f1_score: 0.8591 - precision_4: 0.9123 - recall_4: 0.8194 - val_loss: 3.0622 - val_f1_score: 0.3433 - val_precision_4: 0.3576 - val_recall_4: 0.3375 - lr: 3.9063e-06\n",
      "Epoch 39/100\n",
      "200/200 [==============================] - 21s 106ms/step - loss: 0.3443 - f1_score: 0.8574 - precision_4: 0.9022 - recall_4: 0.8278 - val_loss: 3.0492 - val_f1_score: 0.3411 - val_precision_4: 0.3540 - val_recall_4: 0.3350 - lr: 3.9063e-06\n",
      "Epoch 40/100\n",
      "200/200 [==============================] - 21s 106ms/step - loss: 0.3334 - f1_score: 0.8705 - precision_4: 0.9142 - recall_4: 0.8359 - val_loss: 3.0735 - val_f1_score: 0.3440 - val_precision_4: 0.3560 - val_recall_4: 0.3338 - lr: 3.9063e-06\n",
      "Epoch 40: early stopping\n",
      "===== ===== ===== ===== =====  Model Traninig for: 879.30 second(s) ===== ===== ===== ===== =====  \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from modules.models import Model\n",
    "from modules.dataset import Dataset\n",
    "\n",
    "NUM_FOLDS = 5\n",
    "dataset = Dataset()\n",
    "for fold_num in range(1, NUM_FOLDS + 1):\n",
    "    \n",
    "    # Callbacks\n",
    "    (\n",
    "        model_checkpoint_callback, \n",
    "        early_stop_callback, \n",
    "        reduce_lr_callback, \n",
    "        lr_logging_callback, \n",
    "        tensorboard_callback\n",
    "    ) = get_callbacks(\n",
    "        NAME, weight_option, fold_num\n",
    "    )\n",
    "\n",
    "    # Path for CSV\n",
    "    path = os.path.join(CURRENT_PATH, \"results\", \"history\", EXPERIMENT_NAME, f\"{NAME}_{weight_option}_FOLD_{fold_num}\")\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "\n",
    "    # CSV Logger\n",
    "    csv_logger = CSVLogger(os.path.join(path, f\"history.csv\"))\n",
    "\n",
    "    # Dataset\n",
    "    train_dataset, test_dataset = dataset.get_kfold(fold_num)\n",
    "\n",
    "    # Modeling\n",
    "    transfer_model = tf.keras.applications.efficientnet.EfficientNetB0(\n",
    "        include_top=False, \n",
    "        weights=weight_option,\n",
    "        input_shape=(224, 224, 3),\n",
    "        pooling=None\n",
    "    )\n",
    "\n",
    "    model = Model(\n",
    "        transfer_model,\n",
    "    )\n",
    "    model = model.get_model()\n",
    "    model._name = f\"{EXPERIMENT_NAME}_FOLD_{fold_num}\"\n",
    "    model.summary()\n",
    "\n",
    "    # Record time for training\n",
    "    start = time.time()\n",
    "    \n",
    "    # Visualize\n",
    "    history = model.fit(\n",
    "        train_dataset,\n",
    "        epochs=EPOCHS,\n",
    "        validation_data=test_dataset,\n",
    "        verbose=1, # Show Progress Bar while Traning\n",
    "        callbacks=[model_checkpoint_callback, csv_logger, early_stop_callback, reduce_lr_callback, lr_logging_callback]\n",
    "    )\n",
    "    \n",
    "    end = time.time()\n",
    "    print(\n",
    "        \"===== \" * 5,\n",
    "        \"Model Traninig for: {:.2f} second(s)\".format(end - start),\n",
    "        \"===== \" * 5,\n",
    "        \"\\n\\n\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "37ebf808-192e-4e87-bfef-cc6a686943a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PrefetchDataset element_spec=(TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None, 4), dtype=tf.int64, name=None))>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d4c0b09-b13d-4f22-8b9c-f21b7d819244",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
