{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8cca7809-4a68-4772-a0f7-e6dd2fc87fa5",
   "metadata": {},
   "source": [
    "## Descriptions\n",
    "F1-score for each class using best model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "64adc1c0-0bb7-4ec5-959c-bf05ddaef6c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from modules.dataset import Dataset, LABELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e021fbd1-6f92-4d98-936e-8980c69e85d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: tensorflow_addons in /opt/conda/lib/python3.10/site-packages (0.19.0)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from tensorflow_addons) (21.3)\n",
      "Requirement already satisfied: typeguard>=2.7 in /opt/conda/lib/python3.10/site-packages (from tensorflow_addons) (2.13.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->tensorflow_addons) (3.0.9)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install tensorflow_addons\n",
    "import tensorflow_addons as tfa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6d61b820-f41e-4cd7-9cb8-fd9affe5ca14",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d11093bc-4da6-43c3-924d-8ff032f4109c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Evaluate:\n",
    "    def __init__(self, model_path):\n",
    "        self.y_true = None\n",
    "        self.y_preds = None\n",
    "        self.model_path = model_path\n",
    "        self.model = self.get_model(model_path)\n",
    "        self.best_thresholds = None\n",
    "        self.thresholds_200 = None\n",
    "    \n",
    "    def get_model(self, path):\n",
    "        return tf.keras.models.load_model(path)\n",
    "    \n",
    "    def get_y_true(self, data):\n",
    "        y_true=[]\n",
    "        for X,y in data:\n",
    "            for label in y:\n",
    "                y_true.append(label)\n",
    "        y_true = tf.Variable(y_true)\n",
    "        self.y_true = y_true\n",
    "        return y_true\n",
    "\n",
    "    def get_confusion_metrics(self, y_true, y_preds):\n",
    "        m = tf.keras.metrics.AUC(multi_label=True)\n",
    "        m.update_state(y_true, y_preds)\n",
    "\n",
    "        thresholds = m.thresholds\n",
    "        variables = m.variables\n",
    "        TP = variables[0]\n",
    "        TN = variables[1]\n",
    "        FP = variables[2]\n",
    "        FN = variables[3]\n",
    "        return thresholds, TP, TN, FP, FN\n",
    "\n",
    "    def model_predict(self, test_dataset):\n",
    "        return self.model.predict(test_dataset)\n",
    "\n",
    "    def get_f1_scores_200_thresholds(self, test_dataset):\n",
    "        self.y_true = self.get_y_true(test_dataset)\n",
    "        self.y_preds = self.model_predict(test_dataset)\n",
    "        \n",
    "        confusion_metrics = self.get_confusion_metrics(self.y_true, self.y_preds)\n",
    "        thresholds, TP, TN, FP, FN = confusion_metrics\n",
    "        self.thresholds_200 = thresholds\n",
    "        f1_class_dict = dict()\n",
    "        for i in range(len(thresholds)):\n",
    "            tp, tn, fp, fn = TP[i], TN[i], FP[i], FN[i]\n",
    "            for label_index in range(15):\n",
    "                f1_score = 2*tp[label_index] / (2*tp[label_index] + fp[label_index] + fn[label_index])\n",
    "                try:\n",
    "                    f1_class_dict[LABELS[label_index]].append(f1_score)\n",
    "                except KeyError:\n",
    "                    f1_class_dict[LABELS[label_index]] = [f1_score]\n",
    "        print(LABELS)\n",
    "        return f1_class_dict\n",
    "    \n",
    "    def get_f1_scores(self, test_dataset):\n",
    "        self.y_true = self.get_y_true(test_dataset)\n",
    "        self.y_preds = self.model_predict(test_dataset)\n",
    "        metric = tfa.metrics.MultiLabelConfusionMatrix(num_classes=15)\n",
    "        metric.update_state(self.y_true,\n",
    "                            np.greater_equal(self.y_preds, self.best_thresholds).astype('int8'))\n",
    "        result = metric.result()\n",
    "        \n",
    "        f1_class_dict = dict()\n",
    "        for idx, confusion in enumerate(result):\n",
    "            label = LABELS[idx]\n",
    "            TP, TN, FP, FN = (confusion[1, 1],\n",
    "                              confusion[0, 0],\n",
    "                              confusion[0, 1],\n",
    "                              confusion[1, 0])\n",
    "            f1_score = 2*TP / (2*TP + FP + FN)\n",
    "            f1_class_dict[label] = [f1_score.numpy()]\n",
    "        return f1_class_dict\n",
    "    \n",
    "    def get_precision_scores(self, test_dataset, new_calculate=True):\n",
    "        if new_calculate is True:\n",
    "            self.y_true = self.get_y_true(test_dataset)\n",
    "            self.y_preds = self.model_predict(test_dataset)\n",
    "        metric = tfa.metrics.MultiLabelConfusionMatrix(num_classes=15)\n",
    "        metric.update_state(self.y_true,\n",
    "                            np.greater_equal(self.y_preds, self.best_thresholds).astype('int8'))\n",
    "        result = metric.result()\n",
    "        \n",
    "        precision_class_dict = dict()\n",
    "        for idx, confusion in enumerate(result):\n",
    "            label = LABELS[idx]\n",
    "            TP, TN, FP, FN = (confusion[1, 1],\n",
    "                              confusion[0, 0],\n",
    "                              confusion[0, 1],\n",
    "                              confusion[1, 0])\n",
    "            precision = TP / (TP + FP)\n",
    "            precision_class_dict[label] = [precision.numpy()]\n",
    "        return precision_class_dict\n",
    "    \n",
    "    def get_recall_scores(self, test_dataset, new_calculate=True):\n",
    "        if new_calculate is True:\n",
    "            self.y_true = self.get_y_true(test_dataset)\n",
    "            self.y_preds = self.model_predict(test_dataset)\n",
    "        metric = tfa.metrics.MultiLabelConfusionMatrix(num_classes=15)\n",
    "        metric.update_state(self.y_true,\n",
    "                            np.greater_equal(self.y_preds, self.best_thresholds).astype('int8'))\n",
    "        result = metric.result()\n",
    "        \n",
    "        recall_class_dict = dict()\n",
    "        for idx, confusion in enumerate(result):\n",
    "            label = LABELS[idx]\n",
    "            TP, TN, FP, FN = (confusion[1, 1],\n",
    "                              confusion[0, 0],\n",
    "                              confusion[0, 1],\n",
    "                              confusion[1, 0])\n",
    "            recall = TP / (TP + FN)\n",
    "            recall_class_dict[label] = [recall.numpy()]\n",
    "        return recall_class_dict\n",
    "    \n",
    "    def get_best_threshold(self):\n",
    "        fold_num = int(self.model_path.split(\".\")[0][-1])\n",
    "        test_dataset = datasets[fold_num-1]\n",
    "        f1_scores_dict = self.get_f1_scores_200_thresholds(test_dataset)\n",
    "        best_thresholds_dict = {\"thresholds\": [], \"f1_most\": [], \"label\": []}\n",
    "        for key, value in f1_scores_dict.items():\n",
    "            f1_arg_max = np.argmax(value)\n",
    "            best_thresholds_dict[\"f1_most\"].append(value[f1_arg_max].numpy())\n",
    "            best_thresholds_dict[\"label\"].append(key)\n",
    "            best_thresholds_dict[\"thresholds\"].append(self.thresholds_200[f1_arg_max])\n",
    "        \n",
    "        df = pd.DataFrame(best_thresholds_dict)\n",
    "        df = df.set_index(\"label\")\n",
    "        print(df)\n",
    "        \n",
    "        df_200_thresholds = pd.DataFrame(f1_scores_dict)\n",
    "        \n",
    "        df_200_thresholds.to_csv(\"/home/jovyan/ChestXray-14/results/paper/table3_1/f1_per_thresholds.csv\", index=True)\n",
    "        \n",
    "        df.to_csv(\"/home/jovyan/ChestXray-14/results/paper/table3_1/best_thresholds.csv\", index=True)\n",
    "        self.best_thresholds = df.copy()[\"thresholds\"].values\n",
    "\n",
    "    def __enter__(self):\n",
    "        return self\n",
    "\n",
    "    def __exit__(self, *arg):\n",
    "        # print(\"Exit!\")\n",
    "        self.y_true = None\n",
    "        self.y_preds = None\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fb1d94a6-32a0-4998-b54f-7e7b067df6cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_dataset_5_fold():\n",
    "    dataset = Dataset()\n",
    "    _, test_dataset_fold_1 = dataset.get_kfold(fold_number=1, sample=False)\n",
    "    _, test_dataset_fold_2 = dataset.get_kfold(fold_number=2, sample=False)\n",
    "    _, test_dataset_fold_3 = dataset.get_kfold(fold_number=3, sample=False)\n",
    "    _, test_dataset_fold_4 = dataset.get_kfold(fold_number=4, sample=False)\n",
    "    _, test_dataset_fold_5 = dataset.get_kfold(fold_number=5, sample=False)\n",
    "    return (\n",
    "        test_dataset_fold_1,\n",
    "        test_dataset_fold_2,\n",
    "        test_dataset_fold_3,\n",
    "        test_dataset_fold_4,\n",
    "        test_dataset_fold_5\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a27f05c1-8a12-4b87-b7fb-f3d036f519de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1402/1402 [==============================] - 42s 29ms/step\n",
      "['No Finding', 'Atelectasis', 'Consolidation', 'Infiltration', 'Pneumothorax', 'Edema', 'Emphysema', 'Fibrosis', 'Effusion', 'Pneumonia', 'Pleural_Thickening', 'Cardiomegaly', 'Nodule', 'Mass', 'Hernia']\n",
      "                    thresholds   f1_most\n",
      "label                                   \n",
      "No Finding            0.286432  0.740660\n",
      "Atelectasis           0.150754  0.340299\n",
      "Consolidation         0.110553  0.207992\n",
      "Infiltration          0.201005  0.386318\n",
      "Pneumothorax          0.165829  0.263662\n",
      "Edema                 0.145729  0.222080\n",
      "Emphysema             0.105528  0.147580\n",
      "Fibrosis              0.025126  0.068509\n",
      "Effusion              0.246231  0.482054\n",
      "Pneumonia             0.050251  0.076980\n",
      "Pleural_Thickening    0.105528  0.169416\n",
      "Cardiomegaly          0.216080  0.310933\n",
      "Nodule                0.075377  0.145118\n",
      "Mass                  0.160804  0.218792\n",
      "Hernia                0.005025  0.018711\n",
      "===== Fold 1 =====\n",
      "1402/1402 [==============================] - 41s 29ms/step\n",
      "   No Finding  Atelectasis  Consolidation  Infiltration  Pneumothorax  \\\n",
      "0    0.750886     0.342496       0.193038      0.383263      0.288976   \n",
      "\n",
      "     Edema  Emphysema  Fibrosis  Effusion  Pneumonia  Pleural_Thickening  \\\n",
      "0  0.22634   0.135762  0.064455  0.495286   0.060512            0.177433   \n",
      "\n",
      "   Cardiomegaly    Nodule     Mass    Hernia  \n",
      "0      0.328032  0.155206  0.22751  0.017653  \n",
      "===== Fold 2 =====\n",
      "1402/1402 [==============================] - 41s 29ms/step\n",
      "   No Finding  Atelectasis  Consolidation  Infiltration  Pneumothorax  \\\n",
      "0    0.753198     0.338869       0.213219      0.393012      0.297448   \n",
      "\n",
      "      Edema  Emphysema  Fibrosis  Effusion  Pneumonia  Pleural_Thickening  \\\n",
      "0  0.203846   0.130028  0.066047  0.514138   0.061608            0.165751   \n",
      "\n",
      "   Cardiomegaly    Nodule      Mass    Hernia  \n",
      "0      0.373689  0.155908  0.225757  0.019843  \n",
      "===== Fold 3 =====\n",
      "1402/1402 [==============================] - 41s 29ms/step\n",
      "   No Finding  Atelectasis  Consolidation  Infiltration  Pneumothorax  \\\n",
      "0     0.74066     0.340299       0.207992      0.386318      0.263662   \n",
      "\n",
      "     Edema  Emphysema  Fibrosis  Effusion  Pneumonia  Pleural_Thickening  \\\n",
      "0  0.22208    0.14758  0.068509  0.482054    0.07698            0.169416   \n",
      "\n",
      "   Cardiomegaly    Nodule      Mass    Hernia  \n",
      "0      0.310933  0.145118  0.218792  0.018711  \n",
      "===== Fold 4 =====\n",
      "1402/1402 [==============================] - 41s 29ms/step\n",
      "   No Finding  Atelectasis  Consolidation  Infiltration  Pneumothorax  \\\n",
      "0    0.749626      0.35224       0.212666      0.400829      0.296447   \n",
      "\n",
      "     Edema  Emphysema  Fibrosis  Effusion  Pneumonia  Pleural_Thickening  \\\n",
      "0  0.25239   0.153348  0.072186   0.52129   0.086957            0.155963   \n",
      "\n",
      "   Cardiomegaly    Nodule      Mass    Hernia  \n",
      "0      0.362123  0.162255  0.222559  0.018701  \n",
      "===== Fold 5 =====\n",
      "1402/1402 [==============================] - 41s 29ms/step\n",
      "   No Finding  Atelectasis  Consolidation  Infiltration  Pneumothorax  \\\n",
      "0    0.758701     0.371999       0.213697       0.40137      0.303048   \n",
      "\n",
      "      Edema  Emphysema  Fibrosis  Effusion  Pneumonia  Pleural_Thickening  \\\n",
      "0  0.233229   0.158977  0.063298  0.520569   0.079295            0.191121   \n",
      "\n",
      "   Cardiomegaly   Nodule      Mass    Hernia  \n",
      "0      0.412289  0.15499  0.255536  0.016615  \n"
     ]
    }
   ],
   "source": [
    "model_path = \"/home/jovyan/ChestXray-14/results/models/EfficientNetB0_None_fold_3.h5\"\n",
    "best_model = Evaluate(model_path)\n",
    "\n",
    "datasets = get_test_dataset_5_fold()\n",
    "\n",
    "best_model.get_best_threshold()\n",
    "for fold, test_dataset in enumerate(datasets):\n",
    "    print(f\"===== Fold {fold + 1} =====\")\n",
    "    with best_model:\n",
    "        f1_each_class = best_model.get_f1_scores(test_dataset)\n",
    "        df = pd.DataFrame(f1_each_class)\n",
    "        df.to_csv(\"/home/jovyan/ChestXray-14/results/paper/table3_with_precision_recall_f1/best_model_fold_{}.csv\".format(fold+1), index=False)\n",
    "        \n",
    "        precision_each_class = best_model.get_precision_scores(test_dataset, new_calculate=False)\n",
    "        pd.DataFrame(precision_each_class)\\\n",
    "            .to_csv(\"/home/jovyan/ChestXray-14/results/paper/table3_with_precision_recall_f1/precision/best_model_fold_{}.csv\".format(fold+1), index=False)\n",
    "        \n",
    "        recall_each_class = best_model.get_recall_scores(test_dataset, new_calculate=False)\n",
    "        pd.DataFrame(recall_each_class)\\\n",
    "            .to_csv(\"/home/jovyan/ChestXray-14/results/paper/table3_with_precision_recall_f1/recall/best_model_fold_{}.csv\".format(fold+1), index=False)\n",
    "        \n",
    "        print(df)\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f0a30d5-f707-435f-994c-d0f4dcb2375c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
