{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8cca7809-4a68-4772-a0f7-e6dd2fc87fa5",
   "metadata": {},
   "source": [
    "## Descriptions\n",
    "F1-score for each class using best model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "64adc1c0-0bb7-4ec5-959c-bf05ddaef6c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-27 06:59:39.178787: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    }
   ],
   "source": [
    "from functools import partial\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from modules.dataset import Dataset, LABELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e021fbd1-6f92-4d98-936e-8980c69e85d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: tensorflow_addons in /opt/conda/lib/python3.10/site-packages (0.19.0)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from tensorflow_addons) (21.3)\n",
      "Requirement already satisfied: typeguard>=2.7 in /opt/conda/lib/python3.10/site-packages (from tensorflow_addons) (2.13.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->tensorflow_addons) (3.0.9)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install tensorflow_addons\n",
    "import tensorflow_addons as tfa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d61b820-f41e-4cd7-9cb8-fd9affe5ca14",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d11093bc-4da6-43c3-924d-8ff032f4109c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Evaluate:\n",
    "    def __init__(self, model_path):\n",
    "        self.y_true = None\n",
    "        self.y_preds = None\n",
    "        self.model_path = model_path\n",
    "        self.model = self.get_model(model_path)\n",
    "        self.best_thresholds = None\n",
    "        self.thresholds_200 = None\n",
    "    \n",
    "    def get_model(self, path):\n",
    "        return tf.keras.models.load_model(path)\n",
    "    \n",
    "    def get_y_true(self, data):\n",
    "        y_true=[]\n",
    "        for X,y in data:\n",
    "            for label in y:\n",
    "                y_true.append(label)\n",
    "        y_true = tf.Variable(y_true)\n",
    "        self.y_true = y_true\n",
    "        return y_true\n",
    "\n",
    "    def get_confusion_metrics(self, y_true, y_preds):\n",
    "        m = tf.keras.metrics.AUC(multi_label=True)\n",
    "        m.update_state(y_true, y_preds)\n",
    "\n",
    "        thresholds = m.thresholds\n",
    "        variables = m.variables\n",
    "        TP = variables[0]\n",
    "        TN = variables[1]\n",
    "        FP = variables[2]\n",
    "        FN = variables[3]\n",
    "        return thresholds, TP, TN, FP, FN\n",
    "\n",
    "    def model_predict(self, test_dataset):\n",
    "        return self.model.predict(test_dataset)\n",
    "\n",
    "    def get_f1_scores_200_thresholds(self, test_dataset):\n",
    "        self.y_true = self.get_y_true(test_dataset)\n",
    "        self.y_preds = self.model_predict(test_dataset)\n",
    "        \n",
    "        confusion_metrics = self.get_confusion_metrics(self.y_true, self.y_preds)\n",
    "        thresholds, TP, TN, FP, FN = confusion_metrics\n",
    "        self.thresholds_200 = thresholds\n",
    "        f1_class_dict = dict()\n",
    "        for i in range(len(thresholds)):\n",
    "            tp, tn, fp, fn = TP[i], TN[i], FP[i], FN[i]\n",
    "            for label_index in range(15):\n",
    "                f1_score = 2*tp[label_index] / (2*tp[label_index] + fp[label_index] + fn[label_index])\n",
    "                try:\n",
    "                    f1_class_dict[LABELS[label_index]].append(f1_score)\n",
    "                except KeyError:\n",
    "                    f1_class_dict[LABELS[label_index]] = [f1_score]\n",
    "        print(LABELS)\n",
    "        return f1_class_dict\n",
    "    \n",
    "    def get_f1_scores(self, test_dataset):\n",
    "        self.y_true = self.get_y_true(test_dataset)\n",
    "        self.y_preds = self.model_predict(test_dataset)\n",
    "        metric = tfa.metrics.MultiLabelConfusionMatrix(num_classes=15)\n",
    "        metric.update_state(self.y_true,\n",
    "                            np.greater_equal(self.y_preds, self.best_thresholds).astype('int8'))\n",
    "        result = metric.result()\n",
    "        \n",
    "        f1_class_dict = dict()\n",
    "        for idx, confusion in enumerate(result):\n",
    "            label = LABELS[idx]\n",
    "            TP, TN, FP, FN = (confusion[1, 1],\n",
    "                              confusion[0, 0],\n",
    "                              confusion[0, 1],\n",
    "                              confusion[1, 0])\n",
    "            f1_score = 2*TP / (2*TP + FP + FN)\n",
    "            f1_class_dict[label] = [f1_score.numpy()]\n",
    "        return f1_class_dict\n",
    "        \n",
    "    \n",
    "    def get_best_threshold(self):\n",
    "        fold_num = int(self.model_path.split(\".\")[0][-1])\n",
    "        test_dataset = datasets[fold_num-1]\n",
    "        f1_scores_dict = self.get_f1_scores_200_thresholds(test_dataset)\n",
    "        best_thresholds_dict = {\"thresholds\": [], \"f1_most\": [], \"label\": []}\n",
    "        for key, value in f1_scores_dict.items():\n",
    "            f1_arg_max = np.argmax(value)\n",
    "            best_thresholds_dict[\"f1_most\"].append(value[f1_arg_max].numpy())\n",
    "            best_thresholds_dict[\"label\"].append(key)\n",
    "            best_thresholds_dict[\"thresholds\"].append(self.thresholds_200[f1_arg_max])\n",
    "        \n",
    "        df = pd.DataFrame(best_thresholds_dict)\n",
    "        df = df.set_index(\"label\")\n",
    "        print(df)\n",
    "        \n",
    "        df_200_thresholds = pd.DataFrame(f1_scores_dict)\n",
    "        \n",
    "        df_200_thresholds.to_csv(\"/home/jovyan/ChestXray-14/results/paper/table3_1/f1_per_thresholds.csv\", index=True)\n",
    "        \n",
    "        df.to_csv(\"/home/jovyan/ChestXray-14/results/paper/table3_1/best_thresholds.csv\", index=True)\n",
    "        self.best_thresholds = df.copy()[\"thresholds\"].values\n",
    "\n",
    "    def __enter__(self):\n",
    "        return self\n",
    "\n",
    "    def __exit__(self, *arg):\n",
    "        # print(\"Exit!\")\n",
    "        self.y_true = None\n",
    "        self.y_preds = None\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fb1d94a6-32a0-4998-b54f-7e7b067df6cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_dataset_5_fold():\n",
    "    dataset = Dataset()\n",
    "    _, test_dataset_fold_1 = dataset.get_kfold(fold_number=1, sample=False)\n",
    "    _, test_dataset_fold_2 = dataset.get_kfold(fold_number=2, sample=False)\n",
    "    _, test_dataset_fold_3 = dataset.get_kfold(fold_number=3, sample=False)\n",
    "    _, test_dataset_fold_4 = dataset.get_kfold(fold_number=4, sample=False)\n",
    "    _, test_dataset_fold_5 = dataset.get_kfold(fold_number=5, sample=False)\n",
    "    return (\n",
    "        test_dataset_fold_1,\n",
    "        test_dataset_fold_2,\n",
    "        test_dataset_fold_3,\n",
    "        test_dataset_fold_4,\n",
    "        test_dataset_fold_5\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a27f05c1-8a12-4b87-b7fb-f3d036f519de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1402/1402 [==============================] - 42s 29ms/step\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function pfor.<locals>.f at 0x7fab1c7d9630> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function pfor.<locals>.f at 0x7fab1c7d9630> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "['No Finding', 'Atelectasis', 'Consolidation', 'Infiltration', 'Pneumothorax', 'Edema', 'Emphysema', 'Fibrosis', 'Effusion', 'Pneumonia', 'Pleural_Thickening', 'Cardiomegaly', 'Nodule', 'Mass', 'Hernia']\n",
      "                    thresholds   f1_most\n",
      "label                                   \n",
      "No Finding            0.286432  0.740660\n",
      "Atelectasis           0.150754  0.340299\n",
      "Consolidation         0.110553  0.207992\n",
      "Infiltration          0.201005  0.386318\n",
      "Pneumothorax          0.165829  0.263662\n",
      "Edema                 0.145729  0.222080\n",
      "Emphysema             0.105528  0.147580\n",
      "Fibrosis              0.025126  0.068509\n",
      "Effusion              0.246231  0.482054\n",
      "Pneumonia             0.050251  0.076980\n",
      "Pleural_Thickening    0.105528  0.169416\n",
      "Cardiomegaly          0.216080  0.310933\n",
      "Nodule                0.075377  0.145118\n",
      "Mass                  0.160804  0.218792\n",
      "Hernia                0.005025  0.018711\n",
      "===== Fold 1 =====\n",
      "1402/1402 [==============================] - 40s 28ms/step\n",
      "   No Finding  Atelectasis  Consolidation  Infiltration  Pneumothorax  \\\n",
      "0    0.750886     0.342496       0.193038      0.383263      0.288976   \n",
      "\n",
      "     Edema  Emphysema  Fibrosis  Effusion  Pneumonia  Pleural_Thickening  \\\n",
      "0  0.22634   0.135762  0.064455  0.495286   0.060512            0.177433   \n",
      "\n",
      "   Cardiomegaly    Nodule     Mass    Hernia  \n",
      "0      0.328032  0.155206  0.22751  0.017653  \n",
      "===== Fold 2 =====\n",
      "1402/1402 [==============================] - 40s 29ms/step\n",
      "   No Finding  Atelectasis  Consolidation  Infiltration  Pneumothorax  \\\n",
      "0    0.753198     0.338869       0.213219      0.393012      0.297448   \n",
      "\n",
      "      Edema  Emphysema  Fibrosis  Effusion  Pneumonia  Pleural_Thickening  \\\n",
      "0  0.203846   0.130028  0.066047  0.514138   0.061608            0.165751   \n",
      "\n",
      "   Cardiomegaly    Nodule      Mass    Hernia  \n",
      "0      0.373689  0.155908  0.225757  0.019843  \n",
      "===== Fold 3 =====\n",
      "1402/1402 [==============================] - 40s 29ms/step\n",
      "   No Finding  Atelectasis  Consolidation  Infiltration  Pneumothorax  \\\n",
      "0     0.74066     0.340299       0.207992      0.386318      0.263662   \n",
      "\n",
      "     Edema  Emphysema  Fibrosis  Effusion  Pneumonia  Pleural_Thickening  \\\n",
      "0  0.22208    0.14758  0.068509  0.482054    0.07698            0.169416   \n",
      "\n",
      "   Cardiomegaly    Nodule      Mass    Hernia  \n",
      "0      0.310933  0.145118  0.218792  0.018711  \n",
      "===== Fold 4 =====\n",
      "1402/1402 [==============================] - 41s 29ms/step\n",
      "   No Finding  Atelectasis  Consolidation  Infiltration  Pneumothorax  \\\n",
      "0    0.749626      0.35224       0.212666      0.400829      0.296447   \n",
      "\n",
      "     Edema  Emphysema  Fibrosis  Effusion  Pneumonia  Pleural_Thickening  \\\n",
      "0  0.25239   0.153348  0.072186   0.52129   0.086957            0.155963   \n",
      "\n",
      "   Cardiomegaly    Nodule      Mass    Hernia  \n",
      "0      0.362123  0.162255  0.222559  0.018701  \n",
      "===== Fold 5 =====\n",
      "1402/1402 [==============================] - 40s 29ms/step\n",
      "   No Finding  Atelectasis  Consolidation  Infiltration  Pneumothorax  \\\n",
      "0    0.758701     0.371999       0.213697       0.40137      0.303048   \n",
      "\n",
      "      Edema  Emphysema  Fibrosis  Effusion  Pneumonia  Pleural_Thickening  \\\n",
      "0  0.233229   0.158977  0.063298  0.520569   0.079295            0.191121   \n",
      "\n",
      "   Cardiomegaly   Nodule      Mass    Hernia  \n",
      "0      0.412289  0.15499  0.255536  0.016615  \n"
     ]
    }
   ],
   "source": [
    "model_path = \"/home/jovyan/ChestXray-14/results/models/EfficientNetB0_None_fold_3.h5\"\n",
    "best_model = Evaluate(model_path)\n",
    "\n",
    "datasets = get_test_dataset_5_fold()\n",
    "\n",
    "best_model.get_best_threshold()\n",
    "for fold, test_dataset in enumerate(datasets):\n",
    "    print(f\"===== Fold {fold + 1} =====\")\n",
    "    with best_model:\n",
    "        f1_each_class = best_model.get_f1_scores(test_dataset)\n",
    "        df = pd.DataFrame(f1_each_class)\n",
    "        df.to_csv(\"/home/jovyan/ChestXray-14/results/paper/table3_1/best_model_fold_{}.csv\".format(fold+1), index=False)\n",
    "        print(df)\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f0a30d5-f707-435f-994c-d0f4dcb2375c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
