{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f8279a02-967b-4a26-8245-1e33490e2708",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jovyan/ChestXray-14\n"
     ]
    }
   ],
   "source": [
    "%cd ~/ChestXray-14/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "80a312c9-7f08-4476-bb7a-f22b9e37cca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Chonsawat Path: input_path = \"/content/drive/MyDrive/KKU /Project/Dataset/ChestXray NIH\"\n",
    "Deepnote Path: input_path = \"/datasets/chonsawat-drive/KKU /Project/Dataset/ChestXray NIH\"\n",
    "Elab Path: input_path = \"~/ChestXray-14/dataset/ChestXray NIH\"\n",
    "\"\"\"\n",
    "input_path = \"dataset/ChestXray NIH\"\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from tqdm.notebook import tqdm\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "37083be1-c626-4629-bea8-c7f576843254",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using tensorflow 2.6.2\n"
     ]
    }
   ],
   "source": [
    "STRATEGY = tf.distribute.get_strategy()    \n",
    "BATCH_SIZE = 16\n",
    "IMG_SIZE = 224\n",
    "SEED = 42\n",
    "    \n",
    "print('Using tensorflow %s' % tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d8a398e-32c7-4887-8de6-b9ae70468d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_map = {\n",
    "    'image': tf.io.FixedLenFeature([], tf.string),\n",
    "    'image_id': tf.io.FixedLenFeature([], tf.string),\n",
    "    'No Finding': tf.io.FixedLenFeature([], tf.int64),\n",
    "    'Atelectasis': tf.io.FixedLenFeature([], tf.int64),\n",
    "    'Consolidation': tf.io.FixedLenFeature([], tf.int64),\n",
    "    'Infiltration': tf.io.FixedLenFeature([], tf.int64),\n",
    "    'Pneumothorax': tf.io.FixedLenFeature([], tf.int64),\n",
    "    'Edema': tf.io.FixedLenFeature([], tf.int64),\n",
    "    'Emphysema': tf.io.FixedLenFeature([], tf.int64),\n",
    "    'Fibrosis': tf.io.FixedLenFeature([], tf.int64),\n",
    "    'Effusion': tf.io.FixedLenFeature([], tf.int64),\n",
    "    'Pneumonia': tf.io.FixedLenFeature([], tf.int64),\n",
    "    'Pleural_Thickening': tf.io.FixedLenFeature([], tf.int64),\n",
    "    'Cardiomegaly': tf.io.FixedLenFeature([], tf.int64),\n",
    "    'Nodule': tf.io.FixedLenFeature([], tf.int64),\n",
    "    'Mass': tf.io.FixedLenFeature([], tf.int64),\n",
    "    'Hernia': tf.io.FixedLenFeature([], tf.int64)}\n",
    "\n",
    "\n",
    "def count_data_items(filenames):\n",
    "    return np.sum([int(x[:-6].split('-')[-1]) for x in filenames])\n",
    "\n",
    "\n",
    "def decode_image(image_data):\n",
    "    image = tf.image.decode_jpeg(image_data, channels=1)\n",
    "    image = tf.reshape(image, [IMG_SIZE, IMG_SIZE, 1])\n",
    "    return image\n",
    "\n",
    "\n",
    "def scale_image(image, target):\n",
    "    image = tf.cast(image, tf.float32) / 255.\n",
    "    return image, target\n",
    "\n",
    "\n",
    "def read_tfrecord(example):\n",
    "    example = tf.io.parse_single_example(example, feature_map)\n",
    "    image = decode_image(example['image'])\n",
    "    target = [\n",
    "        example['No Finding'],\n",
    "        example['Atelectasis'],\n",
    "        example['Consolidation'],\n",
    "        example['Infiltration'],\n",
    "        example['Pneumothorax'],\n",
    "        example['Edema'],\n",
    "        example['Emphysema'],\n",
    "        example['Fibrosis'],\n",
    "        example['Effusion'],\n",
    "        example['Pneumonia'],\n",
    "        example['Pleural_Thickening'],\n",
    "        example['Cardiomegaly'],\n",
    "        example['Nodule'],\n",
    "        example['Mass'],\n",
    "        example['Hernia']]\n",
    "    return image, target\n",
    "\n",
    "\n",
    "def data_augment(image, target):\n",
    "    image = tf.image.random_flip_left_right(image, seed=SEED)\n",
    "    image = tf.image.random_flip_up_down(image, seed=SEED)\n",
    "    return image, target\n",
    "\n",
    "\n",
    "def get_dataset(filenames, shuffled=False, repeated=False, \n",
    "                cached=False, augmented=False, distributed=True):\n",
    "    auto = tf.data.experimental.AUTOTUNE\n",
    "    dataset = tf.data.TFRecordDataset(filenames, num_parallel_reads=auto)\n",
    "    dataset = dataset.map(read_tfrecord, num_parallel_calls=auto)\n",
    "    if augmented:\n",
    "        dataset = dataset.map(data_augment, num_parallel_calls=auto)\n",
    "    dataset = dataset.map(scale_image, num_parallel_calls=auto)\n",
    "    if shuffled:\n",
    "        dataset = dataset.shuffle(2048, seed=SEED)\n",
    "    if repeated:\n",
    "        dataset = dataset.repeat()\n",
    "    dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)\n",
    "    if cached:\n",
    "        dataset = dataset.cache()\n",
    "    dataset = dataset.prefetch(auto)\n",
    "    if distributed:\n",
    "        dataset = STRATEGY.experimental_distribute_dataset(dataset)\n",
    "    return dataset\n",
    "\n",
    "\n",
    "def get_model():\n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.applications.EfficientNetB0(\n",
    "            include_top=False,\n",
    "            input_shape=(None, None, 1),\n",
    "            weights=None,\n",
    "            pooling='avg'),\n",
    "        tf.keras.layers.Dense(15, activation='sigmoid')\n",
    "    ])\n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=tf.keras.metrics.AUC(multi_label=True))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f5e56761-1591-4d5a-ae71-ac22eab5011d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-08 12:20:22.179270: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-04-08 12:20:23.051067: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 8003 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB MIG 2g.10gb, pci bus id: 0000:b1:00.0, compute capability: 8.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-08 12:20:28.587691: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2022-04-08 12:20:31.364483: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8201\n",
      "2022-04-08 12:20:32.273528: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2022-04-08 12:20:32.274360: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2022-04-08 12:20:32.274386: W tensorflow/stream_executor/gpu/asm_compiler.cc:77] Couldn't get ptxas version string: Internal: Couldn't invoke ptxas --version\n",
      "2022-04-08 12:20:32.275180: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2022-04-08 12:20:32.275223: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: Failed to launch ptxas\n",
      "Relying on driver to perform ptx compilation. \n",
      "Modify $PATH to customize ptxas location.\n",
      "This message will be only logged once.\n",
      "2022-04-08 12:20:41.099586: I tensorflow/stream_executor/cuda/cuda_blas.cc:1760] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4905/4905 [==============================] - 725s 142ms/step - loss: 0.2108 - auc: 0.6185 - val_loss: 0.2053 - val_auc: 0.6753\n",
      "Epoch 2/2\n",
      "4905/4905 [==============================] - 691s 141ms/step - loss: 0.2015 - auc: 0.6770 - val_loss: 0.1989 - val_auc: 0.6995\n"
     ]
    }
   ],
   "source": [
    "train_filenames = tf.io.gfile.glob(f'{input_path}/data/224x224/train/*.tfrec')\n",
    "val_filenames = tf.io.gfile.glob(f'{input_path}/data/224x224/valid/*.tfrec')\n",
    "test_filenames = tf.io.gfile.glob(f'{input_path}/data/224x224/test/*.tfrec')\n",
    "\n",
    "steps_per_epoch = count_data_items(train_filenames) // BATCH_SIZE\n",
    "validation_steps = count_data_items(val_filenames) // BATCH_SIZE\n",
    "\n",
    "train_dataset = get_dataset(train_filenames, shuffled=True, repeated=True, augmented=True)\n",
    "val_dataset = get_dataset(val_filenames, cached=True)\n",
    "\n",
    "with STRATEGY.scope():\n",
    "    model = get_model()\n",
    "    \n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    epochs=2,\n",
    "    validation_data=val_dataset,\n",
    "    validation_steps=validation_steps,\n",
    "    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a5f0d5c3-eed8-4fd2-853f-200073d990c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(f\"{input_path}/models/EfficientNetB0.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b60ede-333b-4116-bb96-e5ac1c0f7faa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
